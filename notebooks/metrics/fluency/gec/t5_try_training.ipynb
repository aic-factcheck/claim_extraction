{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T5 training test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, DataCollatorWithPadding, TrainingArguments, Trainer, EvalPrediction, T5ForConditionalGeneration\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datasets import Dataset, DatasetDict, load_from_disk, concatenate_datasets\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, classification_report, f1_score\n",
    "from typing import Dict\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataset GUG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"/home/mlynatom/data/gug/gug_annotations.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3129 entries, 0 to 3128\n",
      "Data columns (total 6 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   Id                       3129 non-null   int64  \n",
      " 1   Sentence                 3129 non-null   object \n",
      " 2   Expert Judgement         3129 non-null   int64  \n",
      " 3   Crowd Flower Judgements  3129 non-null   object \n",
      " 4   Average                  3129 non-null   float64\n",
      " 5   Dataset                  3129 non-null   object \n",
      "dtypes: float64(1), int64(2), object(3)\n",
      "memory usage: 146.8+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data[\"Expert Judgement\"] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3019 entries, 0 to 3128\n",
      "Data columns (total 6 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   Id                       3019 non-null   int64  \n",
      " 1   Sentence                 3019 non-null   object \n",
      " 2   Expert Judgement         3019 non-null   int64  \n",
      " 3   Crowd Flower Judgements  3019 non-null   object \n",
      " 4   Average                  3019 non-null   float64\n",
      " 5   Dataset                  3019 non-null   object \n",
      "dtypes: float64(1), int64(2), object(3)\n",
      "memory usage: 165.1+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data[\"Expert Judgement\"] = data[\"Expert Judgement\"] -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "transl_dict = {\n",
    "    1:\"Incomprehensible\",\n",
    "    2:\"Somewhat Comprehensible\",\n",
    "    3:\"Comprehensible\",\n",
    "    4:\"Perfect\"\n",
    "}\n",
    "\n",
    "data[\"Expert Judgement\"] = data[\"Expert Judgement\"].apply(lambda x: transl_dict[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['train', 'test', 'dev'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Dataset.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Comprehensible', 'Somewhat Comprehensible', 'Incomprehensible',\n",
       "       'Perfect'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"Expert Judgement\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data[data[\"Dataset\"] == 'train']\n",
    "dev = data[data[\"Dataset\"] == 'dev']\n",
    "test =data[data[\"Dataset\"] == 'test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1518 entries, 0 to 3127\n",
      "Data columns (total 6 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   Id                       1518 non-null   int64  \n",
      " 1   Sentence                 1518 non-null   object \n",
      " 2   Expert Judgement         1518 non-null   object \n",
      " 3   Crowd Flower Judgements  1518 non-null   object \n",
      " 4   Average                  1518 non-null   float64\n",
      " 5   Dataset                  1518 non-null   object \n",
      "dtypes: float64(1), int64(1), object(4)\n",
      "memory usage: 83.0+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 747 entries, 2 to 3126\n",
      "Data columns (total 6 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   Id                       747 non-null    int64  \n",
      " 1   Sentence                 747 non-null    object \n",
      " 2   Expert Judgement         747 non-null    object \n",
      " 3   Crowd Flower Judgements  747 non-null    object \n",
      " 4   Average                  747 non-null    float64\n",
      " 5   Dataset                  747 non-null    object \n",
      "dtypes: float64(1), int64(1), object(4)\n",
      "memory usage: 40.9+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 754 entries, 1 to 3128\n",
      "Data columns (total 6 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   Id                       754 non-null    int64  \n",
      " 1   Sentence                 754 non-null    object \n",
      " 2   Expert Judgement         754 non-null    object \n",
      " 3   Crowd Flower Judgements  754 non-null    object \n",
      " 4   Average                  754 non-null    float64\n",
      " 5   Dataset                  754 non-null    object \n",
      "dtypes: float64(1), int64(1), object(4)\n",
      "memory usage: 41.2+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(train.info())\n",
    "display(dev.info())\n",
    "display(test.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_hf = Dataset.from_pandas(train)\n",
    "dev_hf = Dataset.from_pandas(dev)\n",
    "test_hf = Dataset.from_pandas(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DatasetDict()\n",
    "dataset[\"train\"] = train_hf\n",
    "dataset[\"validation\"] = dev_hf\n",
    "dataset[\"test\"] = test_hf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Id', 'Sentence', 'Expert Judgement', 'Crowd Flower Judgements', 'Average', 'Dataset', '__index_level_0__'],\n",
       "        num_rows: 1518\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['Id', 'Sentence', 'Expert Judgement', 'Crowd Flower Judgements', 'Average', 'Dataset', '__index_level_0__'],\n",
       "        num_rows: 747\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['Id', 'Sentence', 'Expert Judgement', 'Crowd Flower Judgements', 'Average', 'Dataset', '__index_level_0__'],\n",
       "        num_rows: 754\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.remove_columns(['Crowd Flower Judgements', 'Average', 'Dataset', '__index_level_0__'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Id', 'sentence', 'label'],\n",
       "        num_rows: 1518\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['Id', 'sentence', 'label'],\n",
       "        num_rows: 747\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['Id', 'sentence', 'label'],\n",
       "        num_rows: 754\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset.rename_column(\"Expert Judgement\", \"label\")\n",
    "dataset = dataset.rename_column(\"Sentence\", \"sentence\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4d216f73a5548fab050bbfcc0422a2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/1518 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c680ea9082a4fffa7e2685cb6086f2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/747 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec250c73901b4ebf8d6f17ca503e4280",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/754 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset.save_to_disk(\"/home/mlynatom/data/gug/gug_hf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dataset FCE\n",
    "\n",
    "fce_v2.1.bea19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_json(\"/home/mlynatom/data/fce/fce.train.json\", lines=True)\n",
    "dev = pd.read_json(\"/home/mlynatom/data/fce/fce.dev.json\", lines=True)\n",
    "test = pd.read_json(\"/home/mlynatom/data/fce/fce.test.json\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2116 entries, 0 to 2115\n",
      "Data columns (total 8 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   text      2116 non-null   object\n",
      " 1   age       2104 non-null   object\n",
      " 2   q         2116 non-null   object\n",
      " 3   script-s  2116 non-null   int64 \n",
      " 4   edits     2116 non-null   object\n",
      " 5   l1        2116 non-null   object\n",
      " 6   id        2116 non-null   object\n",
      " 7   answer-s  2114 non-null   object\n",
      "dtypes: int64(1), object(7)\n",
      "memory usage: 132.4+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>age</th>\n",
       "      <th>q</th>\n",
       "      <th>script-s</th>\n",
       "      <th>edits</th>\n",
       "      <th>l1</th>\n",
       "      <th>id</th>\n",
       "      <th>answer-s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dear Sir or Madam,\\n\\nI am writing in order to...</td>\n",
       "      <td>21-25</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>[[0, [[71, 76, 'with', 'RT'], [118, 122, 'saw'...</td>\n",
       "      <td>ca</td>\n",
       "      <td>TR1*0102*2000*01</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Unfortunately, Pat wasn't very good at keeping...</td>\n",
       "      <td>21-25</td>\n",
       "      <td>2</td>\n",
       "      <td>31</td>\n",
       "      <td>[[0, [[233, 233, ',', 'MP'], [249, 249, '\"', '...</td>\n",
       "      <td>ca</td>\n",
       "      <td>TR1*0102*2000*01</td>\n",
       "      <td>5.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10 June 2000\\n\\nDear Manager,\\n\\nI would like ...</td>\n",
       "      <td>26-30</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>[[0, [[238, 238, 'in', 'MT'], [473, 473, 'the'...</td>\n",
       "      <td>ko</td>\n",
       "      <td>TR2*0102*2000*01</td>\n",
       "      <td>3.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fashion of the future\\n\\nPeople will wear this...</td>\n",
       "      <td>26-30</td>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "      <td>[[0, [[71, 76, '', 'UJ'], [91, 91, 'the', 'MD'...</td>\n",
       "      <td>ko</td>\n",
       "      <td>TR2*0102*2000*01</td>\n",
       "      <td>3.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DECEMBER 12TH\\n\\nPRINCIPAL MR. ROBERTSON\\n\\nDE...</td>\n",
       "      <td>16-20</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>[[0, [[61, 65, 'THANK', 'S'], [142, 144, 'ON',...</td>\n",
       "      <td>ca</td>\n",
       "      <td>TR3*0100*2000*02</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2111</th>\n",
       "      <td>If you ask at twenty womans what is their favo...</td>\n",
       "      <td>16-20</td>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "      <td>[[0, [[11, 13, '', 'UT'], [21, 27, 'women', 'I...</td>\n",
       "      <td>it</td>\n",
       "      <td>TR1138*0100*2000*01</td>\n",
       "      <td>3.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2112</th>\n",
       "      <td>Dear Mr. Smith;\\n\\nI am writing this letter to...</td>\n",
       "      <td>0-16</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>[[0, [[14, 15, ',', 'RP'], [45, 49, 'let', 'RV...</td>\n",
       "      <td>tr</td>\n",
       "      <td>TR1139*0102*2000*01</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2113</th>\n",
       "      <td>TECHNOLOGICAL ADVANTAGES\\n\\nTechnology is the ...</td>\n",
       "      <td>0-16</td>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>[[0, [[242, 243, '', 'UD'], [300, 305, 'work',...</td>\n",
       "      <td>tr</td>\n",
       "      <td>TR1139*0102*2000*01</td>\n",
       "      <td>3.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2114</th>\n",
       "      <td>Dear Sir or Madam,\\n\\nI am writing to express ...</td>\n",
       "      <td>21-25</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>[[0, [[63, 68, 'with', 'RT'], [82, 91, 'put on...</td>\n",
       "      <td>it</td>\n",
       "      <td>TR1140*0102*2000*01</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2115</th>\n",
       "      <td>Unfortunately, Pat wasn't very good at keeping...</td>\n",
       "      <td>21-25</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>[[0, [[82, 90, 'reason for', 'RN'], [153, 162,...</td>\n",
       "      <td>it</td>\n",
       "      <td>TR1140*0102*2000*01</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2116 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text    age  q  script-s  \\\n",
       "0     Dear Sir or Madam,\\n\\nI am writing in order to...  21-25  1        31   \n",
       "1     Unfortunately, Pat wasn't very good at keeping...  21-25  2        31   \n",
       "2     10 June 2000\\n\\nDear Manager,\\n\\nI would like ...  26-30  1        29   \n",
       "3     Fashion of the future\\n\\nPeople will wear this...  26-30  3        29   \n",
       "4     DECEMBER 12TH\\n\\nPRINCIPAL MR. ROBERTSON\\n\\nDE...  16-20  1        28   \n",
       "...                                                 ...    ... ..       ...   \n",
       "2111  If you ask at twenty womans what is their favo...  16-20  3        29   \n",
       "2112  Dear Mr. Smith;\\n\\nI am writing this letter to...   0-16  1        24   \n",
       "2113  TECHNOLOGICAL ADVANTAGES\\n\\nTechnology is the ...   0-16  4        24   \n",
       "2114  Dear Sir or Madam,\\n\\nI am writing to express ...  21-25  1        34   \n",
       "2115  Unfortunately, Pat wasn't very good at keeping...  21-25  2        34   \n",
       "\n",
       "                                                  edits  l1  \\\n",
       "0     [[0, [[71, 76, 'with', 'RT'], [118, 122, 'saw'...  ca   \n",
       "1     [[0, [[233, 233, ',', 'MP'], [249, 249, '\"', '...  ca   \n",
       "2     [[0, [[238, 238, 'in', 'MT'], [473, 473, 'the'...  ko   \n",
       "3     [[0, [[71, 76, '', 'UJ'], [91, 91, 'the', 'MD'...  ko   \n",
       "4     [[0, [[61, 65, 'THANK', 'S'], [142, 144, 'ON',...  ca   \n",
       "...                                                 ...  ..   \n",
       "2111  [[0, [[11, 13, '', 'UT'], [21, 27, 'women', 'I...  it   \n",
       "2112  [[0, [[14, 15, ',', 'RP'], [45, 49, 'let', 'RV...  tr   \n",
       "2113  [[0, [[242, 243, '', 'UD'], [300, 305, 'work',...  tr   \n",
       "2114  [[0, [[63, 68, 'with', 'RT'], [82, 91, 'put on...  it   \n",
       "2115  [[0, [[82, 90, 'reason for', 'RN'], [153, 162,...  it   \n",
       "\n",
       "                       id answer-s  \n",
       "0        TR1*0102*2000*01      4.3  \n",
       "1        TR1*0102*2000*01      5.1  \n",
       "2        TR2*0102*2000*01      3.3  \n",
       "3        TR2*0102*2000*01      3.3  \n",
       "4        TR3*0100*2000*02      2.3  \n",
       "...                   ...      ...  \n",
       "2111  TR1138*0100*2000*01      3.3  \n",
       "2112  TR1139*0102*2000*01      3.1  \n",
       "2113  TR1139*0102*2000*01      3.2  \n",
       "2114  TR1140*0102*2000*01      4.3  \n",
       "2115  TR1140*0102*2000*01      4.3  \n",
       "\n",
       "[2116 rows x 8 columns]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.3     293\n",
       "3.2     280\n",
       "3.1     256\n",
       "4.1     223\n",
       "4.2     190\n",
       "4.3     176\n",
       "5.1     152\n",
       "2.3     150\n",
       "2.3T    103\n",
       "2.2      89\n",
       "5.2      71\n",
       "5.3      41\n",
       "2.1      37\n",
       "1.3      28\n",
       "1.2       9\n",
       "0         5\n",
       "S         3\n",
       "1.1       3\n",
       "2.        1\n",
       ".1        1\n",
       "5/1       1\n",
       "1         1\n",
       ".2        1\n",
       "Name: answer-s, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "3.3     26\n",
       "4.1     20\n",
       "3.2     20\n",
       "3.1     15\n",
       "4.3     13\n",
       "4.2     12\n",
       "2.3T    10\n",
       "5.1     10\n",
       "2.3      8\n",
       "2.2      8\n",
       "5.2      5\n",
       "2.1      4\n",
       "1.2      2\n",
       "5.3      2\n",
       "S        2\n",
       ".2       1\n",
       "1.3      1\n",
       "Name: answer-s, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "3.2     25\n",
       "3.1     24\n",
       "3.3     23\n",
       "5.1     20\n",
       "2.3T    19\n",
       "4.1     16\n",
       "5.2     14\n",
       "2.2     11\n",
       "2.3      9\n",
       "2.1      9\n",
       "4.3      8\n",
       "5.3      6\n",
       "4.2      5\n",
       "1.3      3\n",
       "1.2      2\n",
       "Name: answer-s, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(train[\"answer-s\"].value_counts())\n",
    "display(dev[\"answer-s\"].value_counts())\n",
    "display(test[\"answer-s\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_df(data_train):\n",
    "    data_train.dropna(inplace=True)\n",
    "    data_train = data_train[data_train[\"answer-s\"] != \"S\"]\n",
    "    data_train = data_train[data_train[\"answer-s\"] != \"5/1\"]\n",
    "    data_train[\"answer-s\"].replace(\"2.3T\", \"2.3\", inplace=True)\n",
    "    data_train[\"answer-s\"] = pd.to_numeric(data_train[\"answer-s\"], downcast=\"integer\")\n",
    "    data_train[\"answer-s\"] = data_train[\"answer-s\"].astype(int)\n",
    "    data_train.drop([\"age\", \"q\", \"script-s\", \"edits\", \"l1\"], axis=1, inplace=True)\n",
    "    transl_dict = {\n",
    "    0: \"fce_0\",\n",
    "    1: \"fce_1\",\n",
    "    2:\"fce_2\",\n",
    "    3:\"fce_3\",\n",
    "    4:\"fce_4\",\n",
    "    5:\"fce_5\"\n",
    "    }\n",
    "\n",
    "    data_train[\"answer-s\"] = data_train[\"answer-s\"].apply(lambda x: transl_dict[x])\n",
    "\n",
    "    return data_train\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = process_df(train)\n",
    "dev = process_df(dev)\n",
    "test = process_df(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>id</th>\n",
       "      <th>answer-s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dear Sir or Madam,\\n\\nI am writing in order to...</td>\n",
       "      <td>TR1*0102*2000*01</td>\n",
       "      <td>fce_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Unfortunately, Pat wasn't very good at keeping...</td>\n",
       "      <td>TR1*0102*2000*01</td>\n",
       "      <td>fce_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10 June 2000\\n\\nDear Manager,\\n\\nI would like ...</td>\n",
       "      <td>TR2*0102*2000*01</td>\n",
       "      <td>fce_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fashion of the future\\n\\nPeople will wear this...</td>\n",
       "      <td>TR2*0102*2000*01</td>\n",
       "      <td>fce_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DECEMBER 12TH\\n\\nPRINCIPAL MR. ROBERTSON\\n\\nDE...</td>\n",
       "      <td>TR3*0100*2000*02</td>\n",
       "      <td>fce_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2111</th>\n",
       "      <td>If you ask at twenty womans what is their favo...</td>\n",
       "      <td>TR1138*0100*2000*01</td>\n",
       "      <td>fce_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2112</th>\n",
       "      <td>Dear Mr. Smith;\\n\\nI am writing this letter to...</td>\n",
       "      <td>TR1139*0102*2000*01</td>\n",
       "      <td>fce_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2113</th>\n",
       "      <td>TECHNOLOGICAL ADVANTAGES\\n\\nTechnology is the ...</td>\n",
       "      <td>TR1139*0102*2000*01</td>\n",
       "      <td>fce_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2114</th>\n",
       "      <td>Dear Sir or Madam,\\n\\nI am writing to express ...</td>\n",
       "      <td>TR1140*0102*2000*01</td>\n",
       "      <td>fce_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2115</th>\n",
       "      <td>Unfortunately, Pat wasn't very good at keeping...</td>\n",
       "      <td>TR1140*0102*2000*01</td>\n",
       "      <td>fce_4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2098 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text                   id  \\\n",
       "0     Dear Sir or Madam,\\n\\nI am writing in order to...     TR1*0102*2000*01   \n",
       "1     Unfortunately, Pat wasn't very good at keeping...     TR1*0102*2000*01   \n",
       "2     10 June 2000\\n\\nDear Manager,\\n\\nI would like ...     TR2*0102*2000*01   \n",
       "3     Fashion of the future\\n\\nPeople will wear this...     TR2*0102*2000*01   \n",
       "4     DECEMBER 12TH\\n\\nPRINCIPAL MR. ROBERTSON\\n\\nDE...     TR3*0100*2000*02   \n",
       "...                                                 ...                  ...   \n",
       "2111  If you ask at twenty womans what is their favo...  TR1138*0100*2000*01   \n",
       "2112  Dear Mr. Smith;\\n\\nI am writing this letter to...  TR1139*0102*2000*01   \n",
       "2113  TECHNOLOGICAL ADVANTAGES\\n\\nTechnology is the ...  TR1139*0102*2000*01   \n",
       "2114  Dear Sir or Madam,\\n\\nI am writing to express ...  TR1140*0102*2000*01   \n",
       "2115  Unfortunately, Pat wasn't very good at keeping...  TR1140*0102*2000*01   \n",
       "\n",
       "     answer-s  \n",
       "0       fce_4  \n",
       "1       fce_5  \n",
       "2       fce_3  \n",
       "3       fce_3  \n",
       "4       fce_2  \n",
       "...       ...  \n",
       "2111    fce_3  \n",
       "2112    fce_3  \n",
       "2113    fce_3  \n",
       "2114    fce_4  \n",
       "2115    fce_4  \n",
       "\n",
       "[2098 rows x 3 columns]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_hf = Dataset.from_pandas(train)\n",
    "dev_hf = Dataset.from_pandas(dev)\n",
    "test_hf = Dataset.from_pandas(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DatasetDict()\n",
    "dataset[\"train\"] = train_hf\n",
    "dataset[\"validation\"] = dev_hf\n",
    "dataset[\"test\"] = test_hf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'id', 'answer-s', '__index_level_0__'],\n",
       "        num_rows: 2098\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'id', 'answer-s', '__index_level_0__'],\n",
       "        num_rows: 157\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'id', 'answer-s', '__index_level_0__'],\n",
       "        num_rows: 192\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.remove_columns(['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.rename_column(\"answer-s\", \"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.rename_column(\"text\", \"sentence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.rename_column(\"__index_level_0__\", \"Id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8618e3f60b0b489c881b545697943022",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2098 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfe0d6dee4eb48fca73b6d0fddde20c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/157 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ba615c1efee45ddac074a2c363d8518",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/192 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = dataset.map(lambda example : {\"Id\": example[\"Id\"]+100000})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b23d13cd0ff94393b787379c7bdc7e99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/2098 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cbc6e3f94454ce0b36df62a62aa9964",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/157 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2436ca7b11a46109c3c2c181e65f316",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/192 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset.save_to_disk(\"/home/mlynatom/data/fce/fce_hf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"grammarly/coedit-large\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"grammarly/coedit-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"grammarly/coedit-xl\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"grammarly/coedit-xl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### freeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5ForSequenceClassification(\n",
       "  (transformer): T5Model(\n",
       "    (shared): Embedding(32100, 1024)\n",
       "    (encoder): T5Stack(\n",
       "      (embed_tokens): Embedding(32100, 1024)\n",
       "      (block): ModuleList(\n",
       "        (0): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (relative_attention_bias): Embedding(32, 16)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseGatedActDense(\n",
       "                (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "                (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "                (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): NewGELUActivation()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseGatedActDense(\n",
       "                (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "                (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "                (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): NewGELUActivation()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseGatedActDense(\n",
       "                (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "                (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "                (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): NewGELUActivation()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseGatedActDense(\n",
       "                (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "                (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "                (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): NewGELUActivation()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (4): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseGatedActDense(\n",
       "                (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "                (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "                (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): NewGELUActivation()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (5): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseGatedActDense(\n",
       "                (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "                (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "                (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): NewGELUActivation()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (6): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseGatedActDense(\n",
       "                (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "                (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "                (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): NewGELUActivation()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (7): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseGatedActDense(\n",
       "                (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "                (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "                (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): NewGELUActivation()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (8): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseGatedActDense(\n",
       "                (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "                (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "                (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): NewGELUActivation()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (9): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseGatedActDense(\n",
       "                (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "                (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "                (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): NewGELUActivation()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (10): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseGatedActDense(\n",
       "                (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "                (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "                (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): NewGELUActivation()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (11): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseGatedActDense(\n",
       "                (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "                (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "                (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): NewGELUActivation()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (12): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseGatedActDense(\n",
       "                (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "                (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "                (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): NewGELUActivation()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (13): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseGatedActDense(\n",
       "                (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "                (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "                (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): NewGELUActivation()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (14): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseGatedActDense(\n",
       "                (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "                (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "                (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): NewGELUActivation()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (15): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseGatedActDense(\n",
       "                (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "                (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "                (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): NewGELUActivation()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (16): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseGatedActDense(\n",
       "                (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "                (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "                (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): NewGELUActivation()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (17): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseGatedActDense(\n",
       "                (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "                (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "                (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): NewGELUActivation()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (18): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseGatedActDense(\n",
       "                (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "                (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "                (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): NewGELUActivation()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (19): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseGatedActDense(\n",
       "                (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "                (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "                (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): NewGELUActivation()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (20): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseGatedActDense(\n",
       "                (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "                (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "                (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): NewGELUActivation()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (21): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseGatedActDense(\n",
       "                (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "                (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "                (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): NewGELUActivation()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (22): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseGatedActDense(\n",
       "                (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "                (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "                (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): NewGELUActivation()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (23): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseGatedActDense(\n",
       "                (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "                (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "                (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): NewGELUActivation()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (final_layer_norm): T5LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (decoder): T5Stack(\n",
       "      (embed_tokens): Embedding(32100, 1024)\n",
       "      (block): ModuleList(\n",
       "        (0): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (relative_attention_bias): Embedding(32, 16)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerCrossAttention(\n",
       "              (EncDecAttention): T5Attention(\n",
       "                (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (2): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseGatedActDense(\n",
       "                (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "                (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "                (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): NewGELUActivation()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerCrossAttention(\n",
       "              (EncDecAttention): T5Attention(\n",
       "                (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (2): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseGatedActDense(\n",
       "                (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "                (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "                (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): NewGELUActivation()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerCrossAttention(\n",
       "              (EncDecAttention): T5Attention(\n",
       "                (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (2): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseGatedActDense(\n",
       "                (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "                (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "                (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): NewGELUActivation()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerCrossAttention(\n",
       "              (EncDecAttention): T5Attention(\n",
       "                (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (2): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseGatedActDense(\n",
       "                (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "                (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "                (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): NewGELUActivation()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (4): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerCrossAttention(\n",
       "              (EncDecAttention): T5Attention(\n",
       "                (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (2): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseGatedActDense(\n",
       "                (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "                (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "                (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): NewGELUActivation()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (5): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerCrossAttention(\n",
       "              (EncDecAttention): T5Attention(\n",
       "                (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (2): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseGatedActDense(\n",
       "                (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "                (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "                (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): NewGELUActivation()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (6): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerCrossAttention(\n",
       "              (EncDecAttention): T5Attention(\n",
       "                (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (2): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseGatedActDense(\n",
       "                (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "                (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "                (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): NewGELUActivation()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (7): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerCrossAttention(\n",
       "              (EncDecAttention): T5Attention(\n",
       "                (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (2): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseGatedActDense(\n",
       "                (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "                (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "                (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): NewGELUActivation()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (8): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerCrossAttention(\n",
       "              (EncDecAttention): T5Attention(\n",
       "                (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (2): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseGatedActDense(\n",
       "                (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "                (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "                (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): NewGELUActivation()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (9): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerCrossAttention(\n",
       "              (EncDecAttention): T5Attention(\n",
       "                (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (2): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseGatedActDense(\n",
       "                (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "                (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "                (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): NewGELUActivation()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (10): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerCrossAttention(\n",
       "              (EncDecAttention): T5Attention(\n",
       "                (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (2): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseGatedActDense(\n",
       "                (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "                (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "                (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): NewGELUActivation()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (11): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerCrossAttention(\n",
       "              (EncDecAttention): T5Attention(\n",
       "                (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (2): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseGatedActDense(\n",
       "                (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "                (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "                (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): NewGELUActivation()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (12): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerCrossAttention(\n",
       "              (EncDecAttention): T5Attention(\n",
       "                (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (2): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseGatedActDense(\n",
       "                (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "                (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "                (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): NewGELUActivation()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (13): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerCrossAttention(\n",
       "              (EncDecAttention): T5Attention(\n",
       "                (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (2): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseGatedActDense(\n",
       "                (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "                (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "                (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): NewGELUActivation()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (14): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerCrossAttention(\n",
       "              (EncDecAttention): T5Attention(\n",
       "                (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (2): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseGatedActDense(\n",
       "                (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "                (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "                (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): NewGELUActivation()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (15): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerCrossAttention(\n",
       "              (EncDecAttention): T5Attention(\n",
       "                (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (2): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseGatedActDense(\n",
       "                (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "                (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "                (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): NewGELUActivation()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (16): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerCrossAttention(\n",
       "              (EncDecAttention): T5Attention(\n",
       "                (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (2): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseGatedActDense(\n",
       "                (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "                (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "                (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): NewGELUActivation()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (17): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerCrossAttention(\n",
       "              (EncDecAttention): T5Attention(\n",
       "                (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (2): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseGatedActDense(\n",
       "                (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "                (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "                (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): NewGELUActivation()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (18): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerCrossAttention(\n",
       "              (EncDecAttention): T5Attention(\n",
       "                (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (2): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseGatedActDense(\n",
       "                (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "                (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "                (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): NewGELUActivation()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (19): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerCrossAttention(\n",
       "              (EncDecAttention): T5Attention(\n",
       "                (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (2): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseGatedActDense(\n",
       "                (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "                (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "                (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): NewGELUActivation()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (20): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerCrossAttention(\n",
       "              (EncDecAttention): T5Attention(\n",
       "                (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (2): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseGatedActDense(\n",
       "                (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "                (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "                (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): NewGELUActivation()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (21): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerCrossAttention(\n",
       "              (EncDecAttention): T5Attention(\n",
       "                (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (2): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseGatedActDense(\n",
       "                (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "                (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "                (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): NewGELUActivation()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (22): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerCrossAttention(\n",
       "              (EncDecAttention): T5Attention(\n",
       "                (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (2): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseGatedActDense(\n",
       "                (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "                (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "                (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): NewGELUActivation()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (23): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerCrossAttention(\n",
       "              (EncDecAttention): T5Attention(\n",
       "                (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (2): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseGatedActDense(\n",
       "                (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "                (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "                (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): NewGELUActivation()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (final_layer_norm): T5LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (classification_head): T5ClassificationHead(\n",
       "    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (dropout): Dropout(p=0.0, inplace=False)\n",
       "    (out_proj): Linear(in_features=1024, out_features=4, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "\n",
    "for param in model.classification_head.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "for param in model.parameters():\n",
    "    print(f\"{param.requires_grad}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Id': 1,\n",
       " 'sentence': 'If the teacher once entered in to the class she should be well preaperd of what she is going to explain.',\n",
       " 'label': 'Comprehensible'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets_gug = load_from_disk(\"/home/mlynatom/data/gug/gug_hf\")\n",
    "datasets_gug[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence': 'Dear Sir or Madam,\\n\\nI am writing in order to express my disappointment about your musical show \"Over the Rainbow\".\\n\\nI saws the show\\'s advertisement hanging up of a wall in London where I was spending my holiday with some friends. I convinced them to go there with me because I had heard good references about your Company and, above all, about the main star, Danny Brook.\\n\\nThe problems started in the box office, where we asked for the discounts you announced in the advertisement, and the man who was selling the tickets said that they didn\\'t exist.\\n\\nMoreover, the show was delayed forty-five minutes and the worst of all was that Danny Brook had been replaced by another actor.\\n\\nOn the other hand, the theatre restaurant was closed because unknown reasons.\\n\\nYou promised a perfect evening but it became a big disastrous!\\n\\nI would like some kind of explanation and receive my money back. If you don\\'t agree, I will act consequently.\\n\\nI look forward to hearing from you.\\n\\nYours faithfully,',\n",
       " 'label': 'fce_4',\n",
       " 'Id': 100000}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_fce = load_from_disk(\"/home/mlynatom/data/fce/fce_hf\")\n",
    "dataset_fce[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sentence', 'label', 'Id'],\n",
       "        num_rows: 2098\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['sentence', 'label', 'Id'],\n",
       "        num_rows: 157\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['sentence', 'label', 'Id'],\n",
       "        num_rows: 192\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_fce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_train = concatenate_datasets([datasets_gug[\"train\"], dataset_fce[\"train\"]])\n",
    "datasets_validation = concatenate_datasets([datasets_gug[\"validation\"], dataset_fce[\"validation\"]])\n",
    "datasets_test = concatenate_datasets([datasets_gug[\"test\"], dataset_fce[\"test\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = DatasetDict()\n",
    "\n",
    "datasets[\"train\"] = datasets_train\n",
    "datasets[\"validation\"] = datasets_validation\n",
    "datasets[\"test\"] = datasets_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "179894901a284530afb5924006233643",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3616 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e58ed4a3671c4906922eb51f185331b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/904 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47e5791625834fb9a55d247aaf731418",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/946 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "TASK_PREFIX_GUG = \"<gug>Rate the grammaticality: \"\n",
    "TASK_PREFIX_FCE = \"<fce>Rate the answer: \"\n",
    "def tokenize_function(example):\n",
    "    model_inputs = tokenizer(\n",
    "        [TASK_PREFIX_GUG + sentence if s_id < 100000 else TASK_PREFIX_FCE + sentence for sentence, s_id in zip(example[\"sentence\"], example[\"Id\"])],\n",
    "        max_length = 512,\n",
    "        truncation = True,\n",
    "    )\n",
    "    labels = tokenizer(example[\"label\"], max_length=30, truncation=True)\n",
    "\n",
    "    labels[\"input_ids\"] = [\n",
    "                [(l if l != tokenizer.pad_token_id else -100) for l in label] for label in labels[\"input_ids\"]\n",
    "            ]\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "\n",
    "    return model_inputs\n",
    "\n",
    "\n",
    "tokenized_datasets = datasets.map(tokenize_function, remove_columns=[\"Id\", \"sentence\", \"label\"], batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [3,\n",
       "  2,\n",
       "  1744,\n",
       "  122,\n",
       "  3155,\n",
       "  448,\n",
       "  342,\n",
       "  8,\n",
       "  3,\n",
       "  5096,\n",
       "  4992,\n",
       "  10355,\n",
       "  10,\n",
       "  156,\n",
       "  8,\n",
       "  3145,\n",
       "  728,\n",
       "  5136,\n",
       "  16,\n",
       "  12,\n",
       "  8,\n",
       "  853,\n",
       "  255,\n",
       "  225,\n",
       "  36,\n",
       "  168,\n",
       "  4745,\n",
       "  883,\n",
       "  26,\n",
       "  13,\n",
       "  125,\n",
       "  255,\n",
       "  19,\n",
       "  352,\n",
       "  12,\n",
       "  3209,\n",
       "  5,\n",
       "  1],\n",
       " 'attention_mask': [1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1],\n",
       " 'labels': [2570, 22459, 2296, 1]}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 5e-5\n",
    "batch_size = 32\n",
    "num_epochs = 5\n",
    "warmup_ratio = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: WANDB_PROJECT=t5test\n"
     ]
    }
   ],
   "source": [
    "%env WANDB_PROJECT=t5test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainingArguments\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"models/t5_test_instr_fce_gug_xl\",\n",
    "    learning_rate=learning_rate,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=num_epochs,\n",
    "    weight_decay=0.03,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    save_strategy=\"steps\",\n",
    "    eval_steps=100,\n",
    "    save_steps=100,\n",
    "    fp16=False,\n",
    "    report_to=[\"wandb\"],\n",
    "    warmup_ratio=warmup_ratio,\n",
    "    overwrite_output_dir=True,\n",
    "    predict_with_generate=True,\n",
    "    gradient_accumulation_steps=1,\n",
    "    gradient_checkpointing=True,\n",
    "    tf32=True,\n",
    "    bf16=True,\n",
    "    #torch_compile=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred) -> Dict:\n",
    "    logits, labels = pred\n",
    "    preds = np.argmax(logits, axis=1)\n",
    "    accuracy = accuracy_score(labels, preds)\n",
    "    f1 = f1_score(labels, preds, average=\"weighted\")\n",
    "    return {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"f1\": f1\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForSeq2Seq, Seq2SeqTrainer\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model, label_pad_token_id=-100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='565' max='565' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [565/565 10:58, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.322402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.268766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.247980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.279691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.316800</td>\n",
       "      <td>0.278069</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=565, training_loss=0.3008184500500164, metrics={'train_runtime': 659.5108, 'train_samples_per_second': 27.414, 'train_steps_per_second': 0.857, 'total_flos': 3.0433153646985216e+16, 'train_loss': 0.3008184500500164, 'epoch': 5.0})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    #compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='29' max='29' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [29/29 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.2638375759124756,\n",
       " 'eval_runtime': 2.7192,\n",
       " 'eval_samples_per_second': 332.449,\n",
       " 'eval_steps_per_second': 10.665,\n",
       " 'epoch': 5.0}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"/home/mlynatom/models/coedit_L_gug_fce_instr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = T5ForConditionalGeneration.from_pretrained(\"/home/mlynatom/models/coedit_gug/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA A100-SXM4-40GB\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### gug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "pipe = pipeline(\"text2text-generation\", model=\"/home/mlynatom/models/coedit_gug/\", tokenizer=\"grammarly/coedit-large\", framework=\"pt\", device=0, batch_size = 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mlynatom/venvs/py3.10.4/lib/python3.10/site-packages/transformers/generation/utils.py:1260: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "res = pipe(datasets[\"test\"][\"sentence\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = [x[\"generated_text\"] for x in res]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(list(zip(res, datasets[\"test\"][\"label\"])), columns=[\"result\", \"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>result</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Comprehensible</td>\n",
       "      <td>Somewhat Comprehensible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Comprehensible</td>\n",
       "      <td>Incomprehensible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Perfect</td>\n",
       "      <td>Comprehensible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Perfect</td>\n",
       "      <td>Perfect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Somewhat Comprehensible</td>\n",
       "      <td>Somewhat Comprehensible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>Comprehensible</td>\n",
       "      <td>Comprehensible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>Perfect</td>\n",
       "      <td>Perfect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>Comprehensible</td>\n",
       "      <td>Comprehensible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752</th>\n",
       "      <td>Somewhat Comprehensible</td>\n",
       "      <td>Comprehensible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>753</th>\n",
       "      <td>Comprehensible</td>\n",
       "      <td>Comprehensible</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>754 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      result                     test\n",
       "0             Comprehensible  Somewhat Comprehensible\n",
       "1             Comprehensible         Incomprehensible\n",
       "2                    Perfect           Comprehensible\n",
       "3                    Perfect                  Perfect\n",
       "4    Somewhat Comprehensible  Somewhat Comprehensible\n",
       "..                       ...                      ...\n",
       "749           Comprehensible           Comprehensible\n",
       "750                  Perfect                  Perfect\n",
       "751           Comprehensible           Comprehensible\n",
       "752  Somewhat Comprehensible           Comprehensible\n",
       "753           Comprehensible           Comprehensible\n",
       "\n",
       "[754 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_dict = {\n",
    "    \"Incomprehensible\": 1,\n",
    "    \"Somewhat Comprehensible\": 2,\n",
    "    \"Comprehensible\": 3,\n",
    "    \"Perfect\": 4,\n",
    "}\n",
    "\n",
    "df[\"num_result\"] = df.result.apply(lambda x: rename_dict[x])\n",
    "df[\"num_test\"] = df.test.apply(lambda x: rename_dict[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5278514588859416"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = np.sum(df[\"num_result\"]==df[\"num_test\"])/len(df[\"num_test\"])\n",
    "display(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Frequency'>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df[\"num_result\"].plot(kind=\"hist\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Frequency'>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjsAAAGdCAYAAAD0e7I1AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAArBUlEQVR4nO3dfXBUVZ7/8U8ISSBABwMmnRThQZ4DBBQYaEVFQAJkWBCmVhQhalZGN7hAfIDMsirgGkTFhxkEt0ZBdsygzAKzooABJIwSESKRAE4ERANLOnFF0hCXJiT394dF/2wIkHQ66ebwflXdKu69597+3lPHysfTp7tDLMuyBAAAYKgmgS4AAACgIRF2AACA0Qg7AADAaIQdAABgNMIOAAAwGmEHAAAYjbADAACMRtgBAABGaxroAoJBdXW1jh8/rlatWikkJCTQ5QAAgFqwLEunTp1SfHy8mjS59PwNYUfS8ePHlZCQEOgyAACAD44ePap27dpd8jxhR1KrVq0k/dxZNpstwNUAAIDacLlcSkhI8PwdvxTCjuR568pmsxF2AAC4ylxpCQoLlAEAgNEIOwAAwGiEHQAAYDTCDgAAMBphBwAAGI2wAwAAjEbYAQAARiPsAAAAoxF2AACA0Qg7AADAaIQdAABgNMIOAAAwGmEHAAAYjbADAACM1jTQBQAALtZxzgeBLqHOvl2YEugSgBoxswMAAIxG2AEAAEYj7AAAAKMRdgAAgNEIOwAAwGiEHQAAYLSAhp2lS5cqKSlJNptNNptNDodDGzZs8JwfOnSoQkJCvLaHH37Y6x7FxcVKSUlRZGSkYmJi9MQTT+jcuXON/SgAACBIBfR7dtq1a6eFCxeqa9eusixLb7/9tsaNG6c9e/aoV69ekqSHHnpI8+fP91wTGRnp+XdVVZVSUlJkt9u1Y8cOlZSUaOrUqQoLC9Nzzz3X6M8DAACCT0DDztixY732//3f/11Lly7VZ5995gk7kZGRstvtNV7/0Ucf6cCBA9q8ebNiY2PVr18/LViwQLNnz9Yzzzyj8PDwBn8GAAAQ3IJmzU5VVZVWrVqliooKORwOz/F33nlHbdu2Ve/evZWZmamffvrJcy4vL099+vRRbGys51hycrJcLpf2799/yddyu91yuVxeGwAAMFPAfy6isLBQDodDZ86cUcuWLbV27VolJiZKku6991516NBB8fHx2rt3r2bPnq2ioiKtWbNGkuR0Or2CjiTPvtPpvORrZmVlad68eQ30RAAAIJgEPOx0795dBQUFKi8v11/+8helpqYqNzdXiYmJmjZtmqddnz59FBcXp+HDh+vw4cPq3Lmzz6+ZmZmpjIwMz77L5VJCQkK9ngMAAASngL+NFR4eri5duqh///7KyspS37599eqrr9bYdtCgQZKkQ4cOSZLsdrtKS0u92pzfv9Q6H0mKiIjwfALs/AYAAMwU8LBzoerqarnd7hrPFRQUSJLi4uIkSQ6HQ4WFhSorK/O0ycnJkc1m87wVBgAArm0BfRsrMzNTo0ePVvv27XXq1CllZ2dr27Zt2rRpkw4fPqzs7GyNGTNGbdq00d69ezVr1izddtttSkpKkiSNHDlSiYmJmjJlihYtWiSn06m5c+cqPT1dERERgXw0AAAQJAIadsrKyjR16lSVlJQoKipKSUlJ2rRpk+68804dPXpUmzdv1iuvvKKKigolJCRo4sSJmjt3ruf60NBQrV+/Xo888ogcDodatGih1NRUr+/lAQAA17YQy7KsQBcRaC6XS1FRUSovL2f9DoCg0HHOB4Euoc6+XZgS6BJwjant3++gW7MDAADgT4QdAABgNMIOAAAwGmEHAAAYjbADAACMRtgBAABGI+wAAACjEXYAAIDRCDsAAMBohB0AAGA0wg4AADAaYQcAABiNsAMAAIxG2AEAAEYj7AAAAKMRdgAAgNEIOwAAwGiEHQAAYDTCDgAAMBphBwAAGI2wAwAAjEbYAQAARiPsAAAAoxF2AACA0Qg7AADAaIQdAABgNMIOAAAwGmEHAAAYjbADAACMRtgBAABGI+wAAACjEXYAAIDRCDsAAMBohB0AAGA0wg4AADAaYQcAABiNsAMAAIxG2AEAAEYLaNhZunSpkpKSZLPZZLPZ5HA4tGHDBs/5M2fOKD09XW3atFHLli01ceJElZaWet2juLhYKSkpioyMVExMjJ544gmdO3eusR8FAAAEqYCGnXbt2mnhwoXKz8/X7t27NWzYMI0bN0779++XJM2aNUvvv/++Vq9erdzcXB0/flwTJkzwXF9VVaWUlBSdPXtWO3bs0Ntvv60VK1boqaeeCtQjAQCAIBNiWZYV6CJ+KTo6Wi+88IJ+85vf6Prrr1d2drZ+85vfSJL+/ve/q2fPnsrLy9PgwYO1YcMG/frXv9bx48cVGxsrSVq2bJlmz56t77//XuHh4bV6TZfLpaioKJWXl8tmszXYswFAbXWc80GgS6izbxemBLoEXGNq+/c7aNbsVFVVadWqVaqoqJDD4VB+fr4qKys1YsQIT5sePXqoffv2ysvLkyTl5eWpT58+nqAjScnJyXK5XJ7ZoZq43W65XC6vDQAAmCngYaewsFAtW7ZURESEHn74Ya1du1aJiYlyOp0KDw9X69atvdrHxsbK6XRKkpxOp1fQOX/+/LlLycrKUlRUlGdLSEjw70MBAICgEfCw0717dxUUFGjnzp165JFHlJqaqgMHDjToa2ZmZqq8vNyzHT16tEFfDwAABE7TQBcQHh6uLl26SJL69++vXbt26dVXX9Xdd9+ts2fP6uTJk16zO6WlpbLb7ZIku92uzz//3Ot+5z+tdb5NTSIiIhQREeHnJwEAAMEo4DM7F6qurpbb7Vb//v0VFhamLVu2eM4VFRWpuLhYDodDkuRwOFRYWKiysjJPm5ycHNlsNiUmJjZ67QAAIPgEdGYnMzNTo0ePVvv27XXq1CllZ2dr27Zt2rRpk6KiopSWlqaMjAxFR0fLZrPp0UcflcPh0ODBgyVJI0eOVGJioqZMmaJFixbJ6XRq7ty5Sk9PZ+YGAABICnDYKSsr09SpU1VSUqKoqCglJSVp06ZNuvPOOyVJL7/8spo0aaKJEyfK7XYrOTlZr7/+uuf60NBQrV+/Xo888ogcDodatGih1NRUzZ8/P1CPBAAAgkzQfc9OIPA9OwCCDd+zA1zZVfc9OwAAAA2BsAMAAIxG2AEAAEYj7AAAAKMRdgAAgNEIOwAAwGiEHQAAYDTCDgAAMBphBwAAGI2wAwAAjEbYAQAARiPsAAAAoxF2AACA0Qg7AADAaIQdAABgNMIOAAAwGmEHAAAYjbADAACMRtgBAABGI+wAAACjEXYAAIDRCDsAAMBohB0AAGA0wg4AADAaYQcAABiNsAMAAIxG2AEAAEYj7AAAAKMRdgAAgNEIOwAAwGiEHQAAYDTCDgAAMBphBwAAGI2wAwAAjEbYAQAARiPsAAAAoxF2AACA0QIadrKysjRw4EC1atVKMTExGj9+vIqKirzaDB06VCEhIV7bww8/7NWmuLhYKSkpioyMVExMjJ544gmdO3euMR8FAAAEqaaBfPHc3Fylp6dr4MCBOnfunH73u99p5MiROnDggFq0aOFp99BDD2n+/Pme/cjISM+/q6qqlJKSIrvdrh07dqikpERTp05VWFiYnnvuuUZ9HgAAEHwCGnY2btzotb9ixQrFxMQoPz9ft912m+d4ZGSk7HZ7jff46KOPdODAAW3evFmxsbHq16+fFixYoNmzZ+uZZ55ReHh4gz4DAAAIbkG1Zqe8vFySFB0d7XX8nXfeUdu2bdW7d29lZmbqp59+8pzLy8tTnz59FBsb6zmWnJwsl8ul/fv3N07hAAAgaAV0ZueXqqurNXPmTN1yyy3q3bu35/i9996rDh06KD4+Xnv37tXs2bNVVFSkNWvWSJKcTqdX0JHk2Xc6nTW+ltvtltvt9uy7XC5/Pw4AAAgSQRN20tPTtW/fPn3yySdex6dNm+b5d58+fRQXF6fhw4fr8OHD6ty5s0+vlZWVpXnz5tWrXgAAcHUIirexpk+frvXr1+vjjz9Wu3btLtt20KBBkqRDhw5Jkux2u0pLS73anN+/1DqfzMxMlZeXe7ajR4/W9xEAAECQCmjYsSxL06dP19q1a7V161Z16tTpitcUFBRIkuLi4iRJDodDhYWFKisr87TJycmRzWZTYmJijfeIiIiQzWbz2gAAgJkC+jZWenq6srOz9de//lWtWrXyrLGJiopS8+bNdfjwYWVnZ2vMmDFq06aN9u7dq1mzZum2225TUlKSJGnkyJFKTEzUlClTtGjRIjmdTs2dO1fp6emKiIgI5OMBAIAgENCZnaVLl6q8vFxDhw5VXFycZ3v33XclSeHh4dq8ebNGjhypHj166LHHHtPEiRP1/vvve+4RGhqq9evXKzQ0VA6HQ/fdd5+mTp3q9b08AADg2hXQmR3Lsi57PiEhQbm5uVe8T4cOHfThhx/6qywAAGCQoFigDAAA0FAIOwAAwGiEHQAAYLSg+VJBAABwZR3nfBDoEurs24UpAX19ZnYAAIDRCDsAAMBohB0AAGA0wg4AADAaYQcAABiNsAMAAIxG2AEAAEYj7AAAAKMRdgAAgNEIOwAAwGiEHQAAYDTCDgAAMBphBwAAGI2wAwAAjEbYAQAARiPsAAAAo/kUdr755ht/1wEAANAgfAo7Xbp00R133KE//elPOnPmjL9rAgAA8Bufws4XX3yhpKQkZWRkyG6367e//a0+//xzf9cGAABQbz6FnX79+unVV1/V8ePH9dZbb6mkpERDhgxR7969tXjxYn3//ff+rhMAAMAn9Vqg3LRpU02YMEGrV6/W888/r0OHDunxxx9XQkKCpk6dqpKSEn/VCQAA4JN6hZ3du3frn//5nxUXF6fFixfr8ccf1+HDh5WTk6Pjx49r3Lhx/qoTAADAJ019uWjx4sVavny5ioqKNGbMGK1cuVJjxoxRkyY/Z6dOnTppxYoV6tixoz9rBQAAqDOfws7SpUv14IMP6v7771dcXFyNbWJiYvTmm2/WqzgAAID68insHDx48IptwsPDlZqa6svtAQAA/ManNTvLly/X6tWrLzq+evVqvf322/UuCgAAwF98CjtZWVlq27btRcdjYmL03HPP1bsoAAAAf/Ep7BQXF6tTp04XHe/QoYOKi4vrXRQAAIC/+BR2YmJitHfv3ouOf/nll2rTpk29iwIAAPAXn8LOPffco3/5l3/Rxx9/rKqqKlVVVWnr1q2aMWOGJk2a5O8aAQAAfObTp7EWLFigb7/9VsOHD1fTpj/forq6WlOnTmXNDgAACCo+hZ3w8HC9++67WrBggb788ks1b95cffr0UYcOHfxdHwAAQL34FHbO69atm7p16+avWgAAAPzOp7BTVVWlFStWaMuWLSorK1N1dbXX+a1bt/qlOAAAgPryaYHyjBkzNGPGDFVVVal3797q27ev11ZbWVlZGjhwoFq1aqWYmBiNHz9eRUVFXm3OnDmj9PR0tWnTRi1bttTEiRNVWlrq1aa4uFgpKSmKjIxUTEyMnnjiCZ07d86XRwMAAIbxaWZn1apVeu+99zRmzJh6vXhubq7S09M1cOBAnTt3Tr/73e80cuRIHThwQC1atJAkzZo1Sx988IFWr16tqKgoTZ8+XRMmTNCnn34q6edZppSUFNntdu3YsUMlJSWaOnWqwsLCWCwNAAB8X6DcpUuXer/4xo0bvfZXrFihmJgY5efn67bbblN5ebnefPNNZWdna9iwYZJ+/qmKnj176rPPPtPgwYP10Ucf6cCBA9q8ebNiY2PVr18/LViwQLNnz9Yzzzyj8PDwetcJAACuXj69jfXYY4/p1VdflWVZfi2mvLxckhQdHS1Jys/PV2VlpUaMGOFp06NHD7Vv3155eXmSpLy8PPXp00exsbGeNsnJyXK5XNq/f3+Nr+N2u+Vyubw2AABgJp9mdj755BN9/PHH2rBhg3r16qWwsDCv82vWrKnzPaurqzVz5kzdcsst6t27tyTJ6XQqPDxcrVu39mobGxsrp9PpafPLoHP+/PlzNcnKytK8efPqXCMAALj6+BR2WrdurbvuusuvhaSnp2vfvn365JNP/HrfmmRmZiojI8Oz73K5lJCQ0OCvCwAAGp9PYWf58uV+LWL69Olav369tm/frnbt2nmO2+12nT17VidPnvSa3SktLZXdbve0+fzzz73ud/7TWufbXCgiIkIRERF+fQYAABCcfFqzI0nnzp3T5s2b9cYbb+jUqVOSpOPHj+v06dO1vodlWZo+fbrWrl2rrVu3XvRL6v3791dYWJi2bNniOVZUVKTi4mI5HA5JksPhUGFhocrKyjxtcnJyZLPZlJiY6OvjAQAAQ/g0s/Pdd99p1KhRKi4ultvt1p133qlWrVrp+eefl9vt1rJly2p1n/T0dGVnZ+uvf/2rWrVq5VljExUVpebNmysqKkppaWnKyMhQdHS0bDabHn30UTkcDg0ePFiSNHLkSCUmJmrKlClatGiRnE6n5s6dq/T0dGZvAACA718qOGDAAP34449q3ry55/hdd93lNQtzJUuXLlV5ebmGDh2quLg4z/buu+962rz88sv69a9/rYkTJ+q2226T3W73WgAdGhqq9evXKzQ0VA6HQ/fdd5+mTp2q+fPn+/JoAADAMD7N7Pztb3/Tjh07LvoOm44dO+p//ud/an2f2nx0vVmzZlqyZImWLFlyyTYdOnTQhx9+WOvXBQAA1w6fZnaqq6tVVVV10fFjx46pVatW9S4KAADAX3wKOyNHjtQrr7zi2Q8JCdHp06f19NNP1/snJAAAAPzJp7exXnrpJSUnJysxMVFnzpzRvffeq4MHD6pt27b685//7O8aAQAAfOZT2GnXrp2+/PJLrVq1Snv37tXp06eVlpamyZMney1YBgAACDSfwo4kNW3aVPfdd58/awEAAPA7n8LOypUrL3t+6tSpPhUDAADgbz6FnRkzZnjtV1ZW6qefflJ4eLgiIyMJOwAAIGj49GmsH3/80Ws7ffq0ioqKNGTIEBYoAwCAoOLzb2NdqGvXrlq4cOFFsz4AAACB5LewI/28aPn48eP+vCUAAEC9+LRm57//+7+99i3LUklJif7whz/olltu8UthAAAA/uBT2Bk/frzXfkhIiK6//noNGzZML730kj/qAgAA8Aufwk51dbW/6wAAAGgQfl2zAwAAEGx8mtnJyMioddvFixf78hIAAAB+4VPY2bNnj/bs2aPKykp1795dkvT1118rNDRUN910k6ddSEiIf6oEAADwkU9hZ+zYsWrVqpXefvttXXfddZJ+/qLBBx54QLfeeqsee+wxvxYJAADgK5/W7Lz00kvKysryBB1Juu666/Tss8/yaSwAABBUfAo7LpdL33///UXHv//+e506dareRQEAAPiLT2Hnrrvu0gMPPKA1a9bo2LFjOnbsmP7rv/5LaWlpmjBhgr9rBAAA8JlPa3aWLVumxx9/XPfee68qKyt/vlHTpkpLS9MLL7zg1wIBAADqw6ewExkZqddff10vvPCCDh8+LEnq3LmzWrRo4dfiAAAA6qteXypYUlKikpISde3aVS1atJBlWf6qCwAAwC98Cjs//PCDhg8frm7dumnMmDEqKSmRJKWlpfGxcwAAEFR8CjuzZs1SWFiYiouLFRkZ6Tl+9913a+PGjX4rDgAAoL58WrPz0UcfadOmTWrXrp3X8a5du+q7777zS2EAAAD+4NPMTkVFhdeMznknTpxQREREvYsCAADwF5/Czq233qqVK1d69kNCQlRdXa1Fixbpjjvu8FtxAAAA9eXT21iLFi3S8OHDtXv3bp09e1ZPPvmk9u/frxMnTujTTz/1d40AAAA+82lmp3fv3vr66681ZMgQjRs3ThUVFZowYYL27Nmjzp07+7tGAAAAn9V5ZqeyslKjRo3SsmXL9K//+q8NURMAAIDf1HlmJywsTHv37m2IWgAAAPzOp7ex7rvvPr355pv+rgUAAMDvfFqgfO7cOb311lvavHmz+vfvf9FvYi1evNgvxQEAANRXncLON998o44dO2rfvn266aabJElff/21V5uQkBD/VQcAAFBPdQo7Xbt2VUlJiT7++GNJP/88xGuvvabY2NgGKQ4AAKC+6rRm58JfNd+wYYMqKir8WhAAAIA/+bRA+bwLww8AAECwqVPYCQkJuWhNTn3W6Gzfvl1jx45VfHy8QkJCtG7dOq/z999/v+c1z2+jRo3yanPixAlNnjxZNptNrVu3Vlpamk6fPu1zTQAAwCx1WrNjWZbuv/9+z499njlzRg8//PBFn8Zas2ZNre5XUVGhvn376sEHH9SECRNqbDNq1CgtX77cs3/hD41OnjxZJSUlysnJUWVlpR544AFNmzZN2dnZdXk0AABgqDqFndTUVK/9++67r14vPnr0aI0ePfqybSIiImS322s899VXX2njxo3atWuXBgwYIEn6/e9/rzFjxujFF19UfHx8veoDAABXvzqFnV/OsDSWbdu2KSYmRtddd52GDRumZ599Vm3atJEk5eXlqXXr1p6gI0kjRoxQkyZNtHPnTt1111013tPtdsvtdnv2XS5Xwz4EAAAImHotUG5oo0aN0sqVK7VlyxY9//zzys3N1ejRo1VVVSVJcjqdiomJ8bqmadOmio6OltPpvOR9s7KyFBUV5dkSEhIa9DkAAEDg+PQNyo1l0qRJnn/36dNHSUlJ6ty5s7Zt26bhw4f7fN/MzExlZGR49l0uF4EHAABDBfXMzoVuuOEGtW3bVocOHZIk2e12lZWVebU5d+6cTpw4ccl1PtLP64BsNpvXBgAAzHRVhZ1jx47phx9+UFxcnCTJ4XDo5MmTys/P97TZunWrqqurNWjQoECVCQAAgkhA38Y6ffq0Z5ZGko4cOaKCggJFR0crOjpa8+bN08SJE2W323X48GE9+eST6tKli5KTkyVJPXv21KhRo/TQQw9p2bJlqqys1PTp0zVp0iQ+iQUAACQFeGZn9+7duvHGG3XjjTdKkjIyMnTjjTfqqaeeUmhoqPbu3at/+Id/ULdu3ZSWlqb+/fvrb3/7m9d37bzzzjvq0aOHhg8frjFjxmjIkCH6j//4j0A9EgAACDIBndkZOnToZX9yYtOmTVe8R3R0NF8gCAAALumqWrMDAABQV4QdAABgNMIOAAAwGmEHAAAYjbADAACMRtgBAABGC+rfxgJM1nHOB4EuwSffLkwJdAkAUCfM7AAAAKMRdgAAgNEIOwAAwGiEHQAAYDTCDgAAMBphBwAAGI2wAwAAjEbYAQAARiPsAAAAoxF2AACA0Qg7AADAaIQdAABgNMIOAAAwGmEHAAAYjbADAACMRtgBAABGI+wAAACjEXYAAIDRCDsAAMBohB0AAGA0wg4AADAaYQcAABiNsAMAAIxG2AEAAEYj7AAAAKMRdgAAgNEIOwAAwGiEHQAAYDTCDgAAMBphBwAAGI2wAwAAjBbQsLN9+3aNHTtW8fHxCgkJ0bp167zOW5alp556SnFxcWrevLlGjBihgwcPerU5ceKEJk+eLJvNptatWystLU2nT59uxKcAAADBLKBhp6KiQn379tWSJUtqPL9o0SK99tprWrZsmXbu3KkWLVooOTlZZ86c8bSZPHmy9u/fr5ycHK1fv17bt2/XtGnTGusRAABAkGsayBcfPXq0Ro8eXeM5y7L0yiuvaO7cuRo3bpwkaeXKlYqNjdW6des0adIkffXVV9q4caN27dqlAQMGSJJ+//vfa8yYMXrxxRcVHx/faM8CAACCU9Cu2Tly5IicTqdGjBjhORYVFaVBgwYpLy9PkpSXl6fWrVt7go4kjRgxQk2aNNHOnTsveW+32y2Xy+W1AQAAMwVt2HE6nZKk2NhYr+OxsbGec06nUzExMV7nmzZtqujoaE+bmmRlZSkqKsqzJSQk+Ll6AAAQLII27DSkzMxMlZeXe7ajR48GuiQAANBAgjbs2O12SVJpaanX8dLSUs85u92usrIyr/Pnzp3TiRMnPG1qEhERIZvN5rUBAAAzBW3Y6dSpk+x2u7Zs2eI55nK5tHPnTjkcDkmSw+HQyZMnlZ+f72mzdetWVVdXa9CgQY1eMwAACD4B/TTW6dOndejQIc/+kSNHVFBQoOjoaLVv314zZ87Us88+q65du6pTp076t3/7N8XHx2v8+PGSpJ49e2rUqFF66KGHtGzZMlVWVmr69OmaNGkSn8QCAACSAhx2du/erTvuuMOzn5GRIUlKTU3VihUr9OSTT6qiokLTpk3TyZMnNWTIEG3cuFHNmjXzXPPOO+9o+vTpGj58uJo0aaKJEyfqtddea/RnAQAAwSmgYWfo0KGyLOuS50NCQjR//nzNnz//km2io6OVnZ3dEOUBAAADBO2aHQAAAH8g7AAAAKMRdgAAgNEIOwAAwGiEHQAAYDTCDgAAMBphBwAAGI2wAwAAjEbYAQAARiPsAAAAoxF2AACA0Qg7AADAaIQdAABgNMIOAAAwGmEHAAAYjbADAACMRtgBAABGI+wAAACjEXYAAIDRCDsAAMBohB0AAGA0wg4AADAaYQcAABiNsAMAAIxG2AEAAEYj7AAAAKMRdgAAgNEIOwAAwGiEHQAAYDTCDgAAMBphBwAAGI2wAwAAjEbYAQAARiPsAAAAoxF2AACA0Qg7AADAaIQdAABgtKAOO88884xCQkK8th49enjOnzlzRunp6WrTpo1atmypiRMnqrS0NIAVAwCAYBPUYUeSevXqpZKSEs/2ySefeM7NmjVL77//vlavXq3c3FwdP35cEyZMCGC1AAAg2DQNdAFX0rRpU9nt9ouOl5eX680331R2draGDRsmSVq+fLl69uypzz77TIMHD27sUgEAQBAK+pmdgwcPKj4+XjfccIMmT56s4uJiSVJ+fr4qKys1YsQIT9sePXqoffv2ysvLC1S5AAAgyAT1zM6gQYO0YsUKde/eXSUlJZo3b55uvfVW7du3T06nU+Hh4WrdurXXNbGxsXI6nZe9r9vtltvt9uy7XK6GKB8AAASBoA47o0eP9vw7KSlJgwYNUocOHfTee++pefPmPt83KytL8+bN80eJAAAgyAX921i/1Lp1a3Xr1k2HDh2S3W7X2bNndfLkSa82paWlNa7x+aXMzEyVl5d7tqNHjzZg1QAAIJCuqrBz+vRpHT58WHFxcerfv7/CwsK0ZcsWz/mioiIVFxfL4XBc9j4RERGy2WxeGwAAMFNQv431+OOPa+zYserQoYOOHz+up59+WqGhobrnnnsUFRWltLQ0ZWRkKDo6WjabTY8++qgcDgefxAIAAB5BHXaOHTume+65Rz/88IOuv/56DRkyRJ999pmuv/56SdLLL7+sJk2aaOLEiXK73UpOTtbrr78e4KoBAEAwCeqws2rVqsueb9asmZYsWaIlS5Y0UkUAAOBqc1Wt2QEAAKgrwg4AADAaYQcAABiNsAMAAIxG2AEAAEYj7AAAAKMRdgAAgNEIOwAAwGiEHQAAYDTCDgAAMBphBwAAGI2wAwAAjEbYAQAARiPsAAAAoxF2AACA0Qg7AADAaIQdAABgNMIOAAAwGmEHAAAYjbADAACMRtgBAABGI+wAAACjEXYAAIDRCDsAAMBohB0AAGA0wg4AADAaYQcAABitaaALMF3HOR8EuoQ6+3ZhSqBLAADAb5jZAQAARiPsAAAAoxF2AACA0Qg7AADAaIQdAABgNMIOAAAwGmEHAAAYjbADAACMRtgBAABGI+wAAACjGRN2lixZoo4dO6pZs2YaNGiQPv/880CXBAAAgoARYefdd99VRkaGnn76aX3xxRfq27evkpOTVVZWFujSAABAgBkRdhYvXqyHHnpIDzzwgBITE7Vs2TJFRkbqrbfeCnRpAAAgwK76Xz0/e/as8vPzlZmZ6TnWpEkTjRgxQnl5eTVe43a75Xa7Pfvl5eWSJJfL5ff6qt0/+f2eDa0h+gEXuxrHhsT4aCxX4/hgbDQOxsbF97Us67Ltrvqw87//+7+qqqpSbGys1/HY2Fj9/e9/r/GarKwszZs376LjCQkJDVLj1SbqlUBXgGDG+MClMDZwKQ09Nk6dOqWoqKhLnr/qw44vMjMzlZGR4dmvrq7WiRMn1KZNG4WEhPjtdVwulxISEnT06FHZbDa/3ddE9FXd0F+1R1/VHn1Ve/RV7TVkX1mWpVOnTik+Pv6y7a76sNO2bVuFhoaqtLTU63hpaansdnuN10RERCgiIsLrWOvWrRuqRNlsNv5jqCX6qm7or9qjr2qPvqo9+qr2GqqvLjejc95Vv0A5PDxc/fv315YtWzzHqqurtWXLFjkcjgBWBgAAgsFVP7MjSRkZGUpNTdWAAQP0q1/9Sq+88ooqKir0wAMPBLo0AAAQYEaEnbvvvlvff/+9nnrqKTmdTvXr108bN268aNFyY4uIiNDTTz990VtmuBh9VTf0V+3RV7VHX9UefVV7wdBXIdaVPq8FAABwFbvq1+wAAABcDmEHAAAYjbADAACMRtgBAABGI+zUw/bt2zV27FjFx8crJCRE69atu+I127Zt00033aSIiAh16dJFK1asaPA6g0Fd+2rbtm0KCQm5aHM6nY1TcABlZWVp4MCBatWqlWJiYjR+/HgVFRVd8brVq1erR48eatasmfr06aMPP/ywEaoNLF/6asWKFReNq2bNmjVSxYGzdOlSJSUleb7YzeFwaMOGDZe95locU1Ld++paHVM1WbhwoUJCQjRz5szLtmvssUXYqYeKigr17dtXS5YsqVX7I0eOKCUlRXfccYcKCgo0c+ZM/dM//ZM2bdrUwJUGXl376ryioiKVlJR4tpiYmAaqMHjk5uYqPT1dn332mXJyclRZWamRI0eqoqLiktfs2LFD99xzj9LS0rRnzx6NHz9e48eP1759+xqx8sbnS19JP3+T6y/H1XfffddIFQdOu3bttHDhQuXn52v37t0aNmyYxo0bp/3799fY/lodU1Ld+0q6NsfUhXbt2qU33nhDSUlJl20XkLFlwS8kWWvXrr1smyeffNLq1auX17G7777bSk5ObsDKgk9t+urjjz+2JFk//vhjo9QUzMrKyixJVm5u7iXb/OM//qOVkpLidWzQoEHWb3/724YuL6jUpq+WL19uRUVFNV5RQey6666z/vjHP9Z4jjHl7XJ9xZiyrFOnTlldu3a1cnJyrNtvv92aMWPGJdsGYmwxs9OI8vLyNGLECK9jycnJysvLC1BFwa9fv36Ki4vTnXfeqU8//TTQ5QREeXm5JCk6OvqSbRhbP6tNX0nS6dOn1aFDByUkJFzx/9hNVFVVpVWrVqmiouKSP6vDmPpZbfpKYkylp6crJSXlojFTk0CMLSO+Qflq4XQ6L/pW59jYWLlcLv3f//2fmjdvHqDKgk9cXJyWLVumAQMGyO12649//KOGDh2qnTt36qabbgp0eY2murpaM2fO1C233KLevXtfst2lxta1sMbpvNr2Vffu3fXWW28pKSlJ5eXlevHFF3XzzTdr//79ateuXSNW3PgKCwvlcDh05swZtWzZUmvXrlViYmKNba/1MVWXvrqWx5QkrVq1Sl988YV27dpVq/aBGFuEHQSl7t27q3v37p79m2++WYcPH9bLL7+s//zP/wxgZY0rPT1d+/bt0yeffBLoUoJebfvK4XB4/R/6zTffrJ49e+qNN97QggULGrrMgOrevbsKCgpUXl6uv/zlL0pNTVVubu4l/4hfy+rSV9fymDp69KhmzJihnJycoF6UTdhpRHa7XaWlpV7HSktLZbPZmNWphV/96lfX1B/96dOna/369dq+ffsV/+/wUmPLbrc3ZIlBoy59daGwsDDdeOONOnToUANVFzzCw8PVpUsXSVL//v21a9cuvfrqq3rjjTcuanutj6m69NWFrqUxlZ+fr7KyMq8Z96qqKm3fvl1/+MMf5Ha7FRoa6nVNIMYWa3YakcPh0JYtW7yO5eTkXPZ9YPx/BQUFiouLC3QZDc6yLE2fPl1r167V1q1b1alTpytec62OLV/66kJVVVUqLCy8JsbWhaqrq+V2u2s8d62OqUu5XF9d6FoaU8OHD1dhYaEKCgo824ABAzR58mQVFBRcFHSkAI2tBlv6fA04deqUtWfPHmvPnj2WJGvx4sXWnj17rO+++86yLMuaM2eONWXKFE/7b775xoqMjLSeeOIJ66uvvrKWLFlihYaGWhs3bgzUIzSauvbVyy+/bK1bt846ePCgVVhYaM2YMcNq0qSJtXnz5kA9QqN55JFHrKioKGvbtm1WSUmJZ/vpp588baZMmWLNmTPHs//pp59aTZs2tV588UXrq6++sp5++mkrLCzMKiwsDMQjNBpf+mrevHnWpk2brMOHD1v5+fnWpEmTrGbNmln79+8PxCM0mjlz5li5ubnWkSNHrL1791pz5syxQkJCrI8++siyLMbUL9W1r67VMXUpF34aKxjGFmGnHs5/PPrCLTU11bIsy0pNTbVuv/32i67p16+fFR4ebt1www3W8uXLG73uQKhrXz3//PNW586drWbNmlnR0dHW0KFDra1btwam+EZWUz9J8hort99+u6fvznvvvfesbt26WeHh4VavXr2sDz74oHELDwBf+mrmzJlW+/btrfDwcCs2NtYaM2aM9cUXXzR+8Y3swQcftDp06GCFh4db119/vTV8+HDPH2/LYkz9Ul376lodU5dyYdgJhrEVYlmW1XDzRgAAAIHFmh0AAGA0wg4AADAaYQcAABiNsAMAAIxG2AEAAEYj7AAAAKMRdgAAgNEIOwAAwGiEHQAAYDTCDgAAMBphBwAAGI2wAwAAjPb/APjs5fyXzGTrAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df[\"num_test\"].plot(kind=\"hist\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.509326815267549, 5.193873470807909e-51)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scipy import stats\n",
    "\n",
    "corr1 = stats.pearsonr(df[\"num_test\"], df[\"num_result\"])\n",
    "display(corr1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Comprehensible']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Somewhat Comprehensible',\n",
       " 'Incomprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Perfect',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Incomprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Perfect',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Incomprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Incomprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Perfect',\n",
       " 'Incomprehensible',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Incomprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Perfect',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Perfect',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Perfect',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Incomprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Incomprehensible',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Incomprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Incomprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Perfect',\n",
       " 'Incomprehensible',\n",
       " 'Comprehensible',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Perfect',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Perfect',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Incomprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Incomprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Incomprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Incomprehensible',\n",
       " 'Comprehensible',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Perfect',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Perfect',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Incomprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Perfect',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Somewhat Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Perfect',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible',\n",
       " 'Comprehensible']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets[\"test\"][\"label\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### coedit_gug_instr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "pipe = pipeline(\"text2text-generation\", model=\"/home/mlynatom/models/coedit_gug_instr/\", tokenizer=\"grammarly/coedit-large\", framework=\"pt\", device=0, batch_size = 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mlynatom/venvs/py3.10.4/lib/python3.10/site-packages/transformers/generation/utils.py:1260: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "res = pipe([TASK_PREFIX + x for x in datasets[\"test\"][\"sentence\"]])\n",
    "res = [x[\"generated_text\"] for x in res]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>result</th>\n",
       "      <th>test</th>\n",
       "      <th>num_result</th>\n",
       "      <th>num_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Comprehensible</td>\n",
       "      <td>Somewhat Comprehensible</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Comprehensible</td>\n",
       "      <td>Incomprehensible</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Perfect</td>\n",
       "      <td>Comprehensible</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Perfect</td>\n",
       "      <td>Perfect</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Somewhat Comprehensible</td>\n",
       "      <td>Somewhat Comprehensible</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>Comprehensible</td>\n",
       "      <td>Comprehensible</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>Perfect</td>\n",
       "      <td>Perfect</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>Comprehensible</td>\n",
       "      <td>Comprehensible</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752</th>\n",
       "      <td>Somewhat Comprehensible</td>\n",
       "      <td>Comprehensible</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>753</th>\n",
       "      <td>Perfect</td>\n",
       "      <td>Comprehensible</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>754 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      result                     test  num_result  num_test\n",
       "0             Comprehensible  Somewhat Comprehensible           3         2\n",
       "1             Comprehensible         Incomprehensible           3         1\n",
       "2                    Perfect           Comprehensible           4         3\n",
       "3                    Perfect                  Perfect           4         4\n",
       "4    Somewhat Comprehensible  Somewhat Comprehensible           2         2\n",
       "..                       ...                      ...         ...       ...\n",
       "749           Comprehensible           Comprehensible           3         3\n",
       "750                  Perfect                  Perfect           4         4\n",
       "751           Comprehensible           Comprehensible           3         3\n",
       "752  Somewhat Comprehensible           Comprehensible           2         3\n",
       "753                  Perfect           Comprehensible           4         3\n",
       "\n",
       "[754 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.DataFrame(list(zip(res, datasets[\"test\"][\"label\"])), columns=[\"result\", \"test\"])\n",
    "rename_dict = {\n",
    "    \"Incomprehensible\": 1,\n",
    "    \"Somewhat Comprehensible\": 2,\n",
    "    \"Comprehensible\": 3,\n",
    "    \"Perfect\": 4,\n",
    "}\n",
    "\n",
    "df[\"num_result\"] = df.result.apply(lambda x: rename_dict[x])\n",
    "df[\"num_test\"] = df.test.apply(lambda x: rename_dict[x])\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5305039787798409"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = np.sum(df[\"num_result\"]==df[\"num_test\"])/len(df[\"num_test\"])\n",
    "display(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Frequency'>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df[\"num_result\"].plot(kind=\"hist\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Frequency'>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df[\"num_test\"].plot(kind=\"hist\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5500253612109544, 7.72819968478461e-61)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scipy import stats\n",
    "\n",
    "corr1 = stats.pearsonr(df[\"num_test\"], df[\"num_result\"])\n",
    "display(corr1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### codedit gug fce instr L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "pipe = pipeline(\"text2text-generation\", model=\"/home/mlynatom/models/coedit_L_gug_fce_instr\", tokenizer=\"grammarly/coedit-large\", framework=\"pt\", device=0, batch_size = 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mlynatom/venvs/py3.10.4/lib/python3.10/site-packages/transformers/generation/utils.py:1260: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "res = pipe([TASK_PREFIX_GUG + x for x in datasets_gug[\"test\"][\"sentence\"]])\n",
    "res = [x[\"generated_text\"] for x in res]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>result</th>\n",
       "      <th>test</th>\n",
       "      <th>num_result</th>\n",
       "      <th>num_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Comprehensible</td>\n",
       "      <td>Somewhat Comprehensible</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Comprehensible</td>\n",
       "      <td>Incomprehensible</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Perfect</td>\n",
       "      <td>Comprehensible</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Perfect</td>\n",
       "      <td>Perfect</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Somewhat Comprehensible</td>\n",
       "      <td>Somewhat Comprehensible</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>Comprehensible</td>\n",
       "      <td>Comprehensible</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>Perfect</td>\n",
       "      <td>Perfect</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>Comprehensible</td>\n",
       "      <td>Comprehensible</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752</th>\n",
       "      <td>Comprehensible</td>\n",
       "      <td>Comprehensible</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>753</th>\n",
       "      <td>Perfect</td>\n",
       "      <td>Comprehensible</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>754 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      result                     test  num_result  num_test\n",
       "0             Comprehensible  Somewhat Comprehensible           3         2\n",
       "1             Comprehensible         Incomprehensible           3         1\n",
       "2                    Perfect           Comprehensible           4         3\n",
       "3                    Perfect                  Perfect           4         4\n",
       "4    Somewhat Comprehensible  Somewhat Comprehensible           2         2\n",
       "..                       ...                      ...         ...       ...\n",
       "749           Comprehensible           Comprehensible           3         3\n",
       "750                  Perfect                  Perfect           4         4\n",
       "751           Comprehensible           Comprehensible           3         3\n",
       "752           Comprehensible           Comprehensible           3         3\n",
       "753                  Perfect           Comprehensible           4         3\n",
       "\n",
       "[754 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.DataFrame(list(zip(res, datasets[\"test\"][\"label\"])), columns=[\"result\", \"test\"])\n",
    "rename_dict = {\n",
    "    \"Incomprehensible\": 1,\n",
    "    \"Somewhat Comprehensible\": 2,\n",
    "    \"Comprehensible\": 3,\n",
    "    \"Perfect\": 4,\n",
    "}\n",
    "\n",
    "df[\"num_result\"] = df.result.apply(lambda x: rename_dict[x])\n",
    "df[\"num_test\"] = df.test.apply(lambda x: rename_dict[x])\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5755968169761273"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = np.sum(df[\"num_result\"]==df[\"num_test\"])/len(df[\"num_test\"])\n",
    "display(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### coedit gug instr xl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "pipe = pipeline(\"text2text-generation\", model=\"/home/mlynatom/models/coedit_xl_gug_instr\", tokenizer=\"grammarly/coedit-xl\", framework=\"pt\", device=0, batch_size = 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pipe([TASK_PREFIX + x for x in datasets[\"test\"][\"sentence\"]])\n",
    "res = [x[\"generated_text\"] for x in res]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(list(zip(res, datasets[\"test\"][\"label\"])), columns=[\"result\", \"test\"])\n",
    "rename_dict = {\n",
    "    \"Incomprehensible\": 1,\n",
    "    \"Somewhat Comprehensible\": 2,\n",
    "    \"Comprehensible\": 3,\n",
    "    \"Perfect\": 4,\n",
    "}\n",
    "\n",
    "df[\"num_result\"] = df.result.apply(lambda x: rename_dict[x])\n",
    "df[\"num_test\"] = df.test.apply(lambda x: rename_dict[x])\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df[\"num_result\"].plot(kind=\"hist\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df[\"num_test\"].plot(kind=\"hist\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "corr1 = stats.pearsonr(df[\"num_test\"], df[\"num_result\"])\n",
    "display(corr1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
