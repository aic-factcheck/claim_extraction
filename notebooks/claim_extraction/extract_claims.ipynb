{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.chat import SimpleJSONChat\n",
    "\n",
    "PROMPT = \"\"\"# Task Definition\n",
    "You are an experienced expert assistant for extracting factual claims from newspaper articles, transcripts of TV debates etc.\n",
    "Your task is to create a list of all relevant factual claims based on the given Wikipedia excerpt.\n",
    "Claims should be as short as possible, but at the same time, they should be comprehensive enough to allow a conclusion to be drawn from them as to whether the claim is true or not.\n",
    "Your task is not to question the truth of the claims, but only to identify them.\n",
    "A claim should be atomic (only contain one information), decontextualized (not require additional information to be understood), faithful to the source text and fluent (gramatically correct and intelligible).\n",
    "\n",
    "\n",
    "Please, you must always return claims in the following format:\n",
    "```json\n",
    "[\n",
    "     \"Claim 1\",\n",
    "     \"Claim 2\",\n",
    "     ...\n",
    "]\n",
    "```\n",
    "\n",
    "# Few-shot Examples\n",
    "\n",
    "Input:\n",
    "Danny DeVito\n",
    "He currently stars as Frank Reynolds on the FX and FXX sitcom It's Always Sunny in Philadelphia.\n",
    "He directs, produces and appears in graphic, short, horror films for his Internet venture The Blood Factory.\n",
    "DeVito's short stature is the result of multiple epiphyseal dysplasia (Fairbank's disease), a rare genetic disorder that affects bone growth in those afflicted.\n",
    "\n",
    "Output:\n",
    "```json\n",
    "[\n",
    "     \"Danny DeVito has a Internet venture called The Blood Factory.\",\n",
    "     \"Danny DeVito is a film maker.\",\n",
    "     \"Danny DeVito creates short horror films.\",\n",
    "     \"Danny DeVito is a director.\",\n",
    "     \"Danny DeVito works on the Internet.\"\n",
    "]\n",
    "```\n",
    "---\n",
    "\n",
    "Input:\n",
    "Wallander (UK TV series)\n",
    "Wallander is a British television series adapted from the Swedish novelist Henning Mankell's Kurt Wallander novels and starring Kenneth Branagh as the eponymous police inspector.\n",
    "It is the first time the Wallander novels have been adapted into an English-language production.\n",
    "\n",
    "Output:\n",
    "```json\n",
    "[\n",
    "     \"Wallander starred Kenneth Branagh.\",\n",
    "     \"Wallander is a television series.\",\n",
    "     \"Wallander was adapted from the Kurt Wallander novels.\",\n",
    "     \"Wallander is a mystery television series.\"\n",
    "]\n",
    "```\n",
    "---\n",
    "\n",
    "Input:\n",
    "Russell Crowe\n",
    "Although a New Zealand citizen, he has lived most of his life in Australia.\n",
    "He came to international attention for his role as the Roman General Maximus Decimus Meridius in the 2000 historical epic film Gladiator, directed by Ridley Scott, for which Crowe won an Academy Award for Best Actor, a Broadcast Film Critics Association Award for Best Actor, an Empire Award for Best Actor and a London Film Critics Circle Award for Best Actor and 10 further nominations for best actor.\n",
    "Crowe appeared as the tobacco firm whistle blower Jeffrey Wigand in the 1999 film The Insider, for which he received five awards as best actor and seven nominations in the same category.\n",
    "\n",
    "Output:\n",
    "```json\n",
    "[\n",
    "     \"Russell Crowe won four awards for Best Actor for his 2000 performance.\",\n",
    "     \"Russell Crowe was in a film directed by Ridley Scott.\",\n",
    "     \"Russell Crowe has been directed by Ridley Scott.\",\n",
    "     \"Russell Crowe was in a film in 2000.\",\n",
    "     \"Russell Crowe was in a historical epic film.\",\n",
    "     \"Russell Crowe played the Roman General Maximus Decimus Meridius.\",\n",
    "     \"Russell Crowe won an Academy Award.\",\n",
    "     \"Russell Crowe won an award presented by a British magazine.\",\n",
    "     \"Russell Crowe is an actor.\"\n",
    "]\n",
    "```\n",
    "---\n",
    "\"\"\"\n",
    "\n",
    "gpt4 = SimpleJSONChat(PROMPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['At least seven civilians were killed in Israeli strikes in Lebanon.',\n",
       " 'Hezbollah rocket fire killed a soldier in Israel.',\n",
       " 'A woman and two children were killed in Souaneh, Lebanon.',\n",
       " 'At least four members of a family were killed in Nabatieh, Lebanon.',\n",
       " 'At least two Hezbollah fighters were killed in southern Lebanon.',\n",
       " \"Israel's military responded to a deadly rocket attack on northern Israel.\",\n",
       " 'Hezbollah and Israeli forces have exchanged fire almost daily since October.',\n",
       " 'The war between Israel and Hamas in the Gaza Strip started in October.',\n",
       " 'Clashes along the Israel-Lebanon border have raised fears of a wider regional conflict.',\n",
       " 'Rockets were fired towards Netua, Manara, and Safed in northern Israel.',\n",
       " 'One Israeli soldier was killed and seven others were wounded in Safed.',\n",
       " 'Staff-Sergeant Omer Sarah Benjo was identified as the soldier who died.',\n",
       " \"A rocket landed near the gate of Safed's hospital.\",\n",
       " 'Hezbollah claimed it attacked Safed in support of Gaza.',\n",
       " 'The Israel Defense Forces struck Hezbollah targets in response to rocket fire.',\n",
       " 'The IDF targeted military compounds, control rooms, and terror infrastructure.',\n",
       " \"Several targets belonged to Hezbollah's elite Radwan Force.\",\n",
       " 'A Syrian woman and her two sons were killed in a strike on a home in Souaneh.',\n",
       " 'One man was killed and 10 others were injured in Aadchit.',\n",
       " 'Hassan Ali Najm, a Hezbollah fighter, was confirmed dead by the group.',\n",
       " 'Four members of the same family were killed in a subsequent strike in Lebanon.',\n",
       " 'The family killed had no links to Hezbollah.',\n",
       " 'Israel is not interested in a war on two fronts, according to an Israeli government spokesperson.',\n",
       " 'Tens of thousands of Israelis are displaced in the north.',\n",
       " \"The IDF's chief of staff said there are achievements striking Hezbollah in Lebanon.\",\n",
       " \"Hezbollah leader Hassan Nasrallah warned of a 'million evacuees' from northern Israel if war widens.\",\n",
       " 'Hezbollah will only cease fire when there is a ceasefire in Gaza.']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_text=\"\"\"At least seven civilians have been killed in Israeli strikes in Lebanon, security sources say, after Hezbollah rocket fire killed a soldier in Israel.\n",
    "A woman and two children were killed in Souaneh, and at least four members of a family were later killed in Nabatieh.\n",
    "At least two Hezbollah fighters were also killed in attacks in southern Lebanon, the group said.\n",
    "Israel's military said it hit Hezbollah infrastructure in response to a deadly rocket attack on northern Israel.\n",
    "Hezbollah fighters have exchanged fire with Israeli forces almost every day along the border since the start of the war between Israel and the Palestinian group Hamas in the Gaza Strip in October.\n",
    "The clashes have raised fears of a wider regional conflict.\n",
    "'We are surrounded': Guarding the Middle East's most dangerous border\n",
    "On Wednesday morning, sirens sounded across northern Israel as barrages of rockets were fired towards the border communities of Netua and Manara, and the town of Safed, which is 14 km (9 miles) south of the frontier.\n",
    "One Israeli soldier was killed and seven others were wounded after their base in Safed was hit by rockets, Israeli media and emergency services said. The soldier who died was later identified as Staff-Sergeant Omer Sarah Benjo.\n",
    "A video showed that another rocket landed near the gate of Safed's hospital.\n",
    "Hezbollah later claimed it had attacked an \"enemy position\" in Safed \"in support of the people and resistance of Gaza which is being subjected to brutal Zionist aggression with a US green light\".\n",
    "In the afternoon, the Israel Defense Forces (IDF) announced that fighter jets had \"struck a series of Hezbollah terror targets\" in Souaneh, Aadchit, Jabal al-Braij, Kfar Houneh and Kfar Dunin in response to the rocket fire.\n",
    "Hezbollah leader Hassan Nasrallah addresses his supporters in a televised speech, at a rally in Beirut, Lebanon (13 February 2024)\n",
    "IMAGE SOURCE, REUTERS\n",
    "Image caption,\n",
    "Hezbollah leader Hassan Nasrallah said it would only cease fire \"when the aggression stops and there is a ceasefire in Gaza\"\n",
    "\"Among the targets struck were military compounds, operational control rooms, and terror infrastructure,\" it said, adding that several targets belonged to Hezbollah's elite Radwan Force, whose well-trained members are considered the group's special forces.\n",
    "Lebanon's state-run National News Agency (NNA) said a strike on a home in Souaneh killed a Syrian woman, Rawaa al-Mohammed, and her two sons, Hassan Mohsen, 13, and Amir Mohsen, two.\n",
    "Video from the town showed residents inspecting the rubble of at least one destroyed building and the burned-out wreckage of a car.\n",
    "NNA also reported that one man was killed and 10 other people were injured in Aadchit. It named the dead man as Hassan Ali Najm, a Hezbollah fighter whose death the group confirmed in a statement on Telegram.\n",
    "Later on Wednesday, a security source told AFP four members of the same family, including two women, were killed in a subsequent strike. The source said they had no links to Hezbollah.\n",
    "\"As we have made clear time and time again, Israel is not interested in a war on two fronts. But if provoked, we will respond forcefully,\" Israeli government spokesperson Ilana Stein told Reuters news agency.\n",
    "\"The current reality, where tens of thousands of Israelis are displaced [in the north] and cannot return to their homes, is unbearable. They must be able to return home and live in peace and security.\"\n",
    "The IDF's chief of staff, Lt Gen Herzi Halevi, meanwhile told the heads of northern municipalities: \"There are great achievements striking Hezbollah in Lebanon, but we continue to operate - this is not the time to stop.\n",
    "\"We are intensifying the strikes all the time, and Hezbollah are paying an increasingly heavy price.\"\n",
    "On Tuesday, Hezbollah leader Hassan Nasrallah warned Israeli leaders in a speech that launching a war against the group would result in a \"million evacuees\" from northern Israel.\n",
    "\"To those who threaten us with a widening of the war: if you widen, we will too,\" he said, adding that \"those who think the resistance might be afraid are very mistaken\".\n",
    "He also vowed that Hezbollah would only cease fire \"when the aggression stops and there is a ceasefire in Gaza\".\"\"\"\n",
    "gpt4(sample_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-02-15 01:20:43,942] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-15 01:20:46.180362: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-15 01:20:47.589325: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /mnt/appl/software/Python/3.10.4-GCCcore-11.3.0-bare/lib:/mnt/appl/software/libffi/3.4.2-GCCcore-11.3.0/lib64:/mnt/appl/software/XZ/5.2.5-GCCcore-11.3.0/lib:/mnt/appl/software/SQLite/3.38.3-GCCcore-11.3.0/lib:/mnt/appl/software/Tcl/8.6.12-GCCcore-11.3.0/lib:/mnt/appl/software/libreadline/8.1.2-GCCcore-11.3.0/lib:/mnt/appl/software/ncurses/6.3-GCCcore-11.3.0/lib:/mnt/appl/software/bzip2/1.0.8-GCCcore-11.3.0/lib:/mnt/appl/software/binutils/2.38-GCCcore-11.3.0/lib:/mnt/appl/software/zlib/1.2.12-GCCcore-11.3.0/lib:/mnt/appl/software/GCCcore/11.3.0/lib64\n",
      "2024-02-15 01:20:47.589432: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /mnt/appl/software/Python/3.10.4-GCCcore-11.3.0-bare/lib:/mnt/appl/software/libffi/3.4.2-GCCcore-11.3.0/lib64:/mnt/appl/software/XZ/5.2.5-GCCcore-11.3.0/lib:/mnt/appl/software/SQLite/3.38.3-GCCcore-11.3.0/lib:/mnt/appl/software/Tcl/8.6.12-GCCcore-11.3.0/lib:/mnt/appl/software/libreadline/8.1.2-GCCcore-11.3.0/lib:/mnt/appl/software/ncurses/6.3-GCCcore-11.3.0/lib:/mnt/appl/software/bzip2/1.0.8-GCCcore-11.3.0/lib:/mnt/appl/software/binutils/2.38-GCCcore-11.3.0/lib:/mnt/appl/software/zlib/1.2.12-GCCcore-11.3.0/lib:/mnt/appl/software/GCCcore/11.3.0/lib64\n",
      "2024-02-15 01:20:47.589440: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "/home/ullriher/venvs/2023feb/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:433: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Israelis have been fighting Hezbollah. Israelis have been fighting in Lebanon. Israelis have been fighting in Lebanon. Israelis have been fighting in Lebanon.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import torch\n",
    "t5_path = \"/home/ullriher/ullriher/models/claim_extraction/paper/_SENTENCE_CONTEXT/multiclaim/t5-small-finetuned-xsum_feversum_sentence_context2claims_bs8_ep35\"\n",
    "t5_ = AutoModelForSeq2SeqLM.from_pretrained(t5_path)\n",
    "t5_tokenizer = AutoTokenizer.from_pretrained(t5_path)\n",
    "\n",
    "# with t5.generate, get the output and then use the tokenizer.decode to get the output\n",
    "def t5(input_text, max_length=512):\n",
    "    input_ids = t5_tokenizer.encode(input_text, return_tensors=\"pt\", max_length=max_length, truncation=True)\n",
    "    output = t5_.generate(input_ids, max_length=max_length, num_return_sequences=1, early_stopping=True)\n",
    "    return t5_tokenizer.decode(output[0], skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
    "\n",
    "t5(sample_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "t5_diverse_path = \"/home/ullriher/ullriher/models/claim_extraction/paper/_SENTENCE_CONTEXT/t5-small-finetuned-xsum_feversum_sentence_context2claim_bs8_ep30\"\n",
    "t5_diverse_ = AutoModelForSeq2SeqLM.from_pretrained(t5_diverse_path)\n",
    "t5_diverse_tokenizer = AutoTokenizer.from_pretrained(t5_diverse_path)\n",
    "\n",
    "def t5_diverse(input_text, num_claims=7, max_length=512):\n",
    "    tokens = t5_diverse_tokenizer(input_text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    input_ids = tokens['input_ids'].to(t5_diverse_.device)\n",
    "    attention_mask = tokens['attention_mask'].to(t5_diverse_.device) if 'attention_mask' in tokens else None\n",
    "\n",
    "    # Generation settin\n",
    "    max_length = 64  # Adjust based on your requirements\n",
    "\n",
    "    # Generate output sequences\n",
    "    output_sequences = t5_diverse_.generate(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=attention_mask,\n",
    "        max_length=max_length,\n",
    "        num_beams=num_claims,\n",
    "        num_beam_groups=num_claims,  # Adjust based on desired diversity\n",
    "        num_return_sequences=num_claims,\n",
    "        diversity_penalty=1.0,  # Adjust based on desired diversity\n",
    "    )\n",
    "\n",
    "    # Decode generated sequences into text\n",
    "    return t5_diverse_tokenizer.batch_decode(output_sequences, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Israeli media and emergency services say at least seven people have been killed.',\n",
       " \"Israel's military has said it hit Hezbollah infrastructure.\",\n",
       " 'At least two Hezbollah fighters were killed in southern Lebanon.',\n",
       " 'One Israeli soldier was killed in Souaneh.',\n",
       " 'The Israeli military has said it hit Hezbollah infrastructure.',\n",
       " 'Israeli media say a Hezbollah rocket attack killed a soldier.',\n",
       " 'At least seven Israeli soldiers were killed in Israeli strikes.',\n",
       " 'Israel has said it hit Hezbollah infrastructure.',\n",
       " 'Israeli media and emergency services say Hezbollah attacked the border communities of Netua and Manara.',\n",
       " 'Israeli media reports that Israeli fighters have killed at least two Hezbollah fighters.',\n",
       " 'There are fears of a wider regional conflict.',\n",
       " 'Two Hezbollah fighters were killed in southern Lebanon.',\n",
       " 'Hezbollah has attacked infrastructure.',\n",
       " 'A soldier was killed in Souaneh.',\n",
       " \"Israel's military has said it hit Hezbollah infrastructure in response to a deadly rocket attack.\",\n",
       " 'Israelis have attacked Hezbollah infrastructure in southern Lebanon.',\n",
       " 'Two Hezbollah fighters have been killed in southern Lebanon.',\n",
       " 'Israelis have been fighting Hezbollah.',\n",
       " 'Israel is a military force.',\n",
       " 'The Israeli government is investigating the Israeli attack on Safed.',\n",
       " 'Palestinians are fighting Hezbollah.',\n",
       " 'At least seven people have been killed in Israel.',\n",
       " 'Israeli military has said it hit Hezbollah infrastructure.',\n",
       " 'One Israeli soldier was killed in Souaneh.',\n",
       " 'The Israel Defense Forces is investigating the Israeli attack on Safed.',\n",
       " \"Three people were killed by Israeli rockets in Safed, Israel's media said.\",\n",
       " 'A Palestinian official died in Safed.',\n",
       " 'A soldier was killed in Souaneh.',\n",
       " 'Israel has said it hit Hezbollah infrastructure.',\n",
       " 'Two Hezbollah fighters were killed in attacks in southern Lebanon.',\n",
       " 'Israel has said it attacked Hezbollah infrastructure in response to a deadly rocket attack.',\n",
       " 'One Israeli soldier was killed.',\n",
       " 'One Israeli soldier was killed in Souaneh.']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t5_diverse(sample_text,num_claims=33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ullriher/venvs/2023feb/lib/python3.10/site-packages/thinc/compat.py:36: UserWarning: 'has_mps' is deprecated, please use 'torch.backends.mps.is_built()'\n",
      "  hasattr(torch, \"has_mps\")\n",
      "/home/ullriher/venvs/2023feb/lib/python3.10/site-packages/thinc/compat.py:37: UserWarning: 'has_mps' is deprecated, please use 'torch.backends.mps.is_built()'\n",
      "  and torch.has_mps  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "from utils.ntbutils import *\n",
    "load_user_libs()\n",
    "from collections import Counter, OrderedDict\n",
    "import ujson\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "import sqlite3\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "from typing import Dict, List, Set\n",
    "import unicodedata\n",
    "import uuid\n",
    "\n",
    "from aic_nlp_utils.json import read_jsonl, read_json, write_json, write_jsonl\n",
    "from aic_nlp_utils.fever import fever_detokenize, import_fever_corpus_from_sqlite\n",
    "from simpletransformers.seq2seq import Seq2SeqModel, Seq2SeqArgs\n",
    "import stanza\n",
    "# stanza.download(\"en\")\n",
    "\n",
    "sys.path.append('Claim_Generation')\n",
    "from T5_QG import pipeline\n",
    "from distractor_generation import Distractor_Generation\n",
    "\n",
    "QACG_ROOT = \"/home/ullriher/ullriher/data/qacg\"\n",
    "Path(QACG_ROOT).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = sample_text\n",
    "\n",
    "def extract_ners(corpus_recs, ner_json):\n",
    "    # for each text gives a triplet (ner, ner_type, ner-ner_type count in text)\n",
    "    # the triplets are sorted by decreasing count\n",
    "    stanza_nlp = stanza.Pipeline('en', use_gpu = True, processors=\"tokenize,ner\")\n",
    "    entity_dict = OrderedDict()\n",
    "    for l in tqdm(corpus_recs):\n",
    "        text = l[\"text\"]\n",
    "        pass_doc = stanza_nlp(text)\n",
    "        ner_pairs = [(ent.text, ent.type) for ent in pass_doc.ents] # text-type pairs\n",
    "        ner_cnts = Counter(ner_pairs) # their \n",
    "        ners_unique_with_counts =  [(p[0], p[1], ner_cnts[(p[0], p[1])]) for p in set(ner_pairs)]\n",
    "        ners_unique_with_counts = sorted(ners_unique_with_counts, key=lambda n: -n[2])\n",
    "        entity_dict[l[\"id\"]] = ners_unique_with_counts\n",
    "    write_json(ner_json, entity_dict)\n",
    "    \n",
    "\n",
    "\n",
    "def generate_qas(corpus_recs, ner_json, qas_json):\n",
    "    # QG NLP object\n",
    "    gpu_index = 0\n",
    "\n",
    "    print('Loading QG module >>>>>>>>')\n",
    "    qg_nlp = pipeline(\"question-generation\", model='valhalla/t5-base-qg-hl', qg_format=\"highlight\", gpu_index = gpu_index)\n",
    "    print('QG module loaded.')\n",
    "    \n",
    "    ners = read_json(ner_json)\n",
    "\n",
    "    qas = OrderedDict()\n",
    "    invalid_sample = 0\n",
    "    for l in tqdm(corpus_recs):\n",
    "        entities = ners[str(l['id'])]\n",
    "\n",
    "        # create a batch\n",
    "        sources, answers = [], []\n",
    "        for ent_text, ent_type, ent_cnt in entities:\n",
    "            sources.append(l['text'])\n",
    "            answers.append(ent_text)\n",
    "            \n",
    "        # question generation\n",
    "        if len(sources) > 0 and len(sources) == len(answers):\n",
    "            results = []\n",
    "            try:\n",
    "                results = qg_nlp.batch_qg_with_answer(sources, answers)\n",
    "            except:\n",
    "                invalid_sample += 1\n",
    "\n",
    "            if len(results) == 0:\n",
    "                continue\n",
    "            \n",
    "            # save results\n",
    "            result_for_sample = {}\n",
    "            for ind, QA in enumerate(results):\n",
    "                ent_text, ent_type, _ = entities[ind]\n",
    "                question = QA['question']\n",
    "                answer = QA['answer']\n",
    "                result_for_sample[f'{ent_text}:::{ent_type}'] = [question, answer]\n",
    "\n",
    "            qas[str(l['id'])] = result_for_sample\n",
    "        else:\n",
    "            invalid_sample += 1\n",
    "\n",
    "    print(f'#invalid samples: {invalid_sample}')\n",
    "    Path(qas_json).parent.mkdir(parents=True, exist_ok=True)\n",
    "    write_json(qas_json, qas)\n",
    "\n",
    "\n",
    "class ClaimGenerator:\n",
    "    def __init__(self, corpus_recs, ner_json, qas_json, QA2D_model_path, sense_to_vec_path, gpu_index=0):\n",
    "        # QA2D model object\n",
    "        print('Loading QA2D module >>>>>>>>')\n",
    "        model_args = Seq2SeqArgs()\n",
    "        model_args.max_length = 64\n",
    "        model_args.silent = True\n",
    "\n",
    "        self.QA2D_model = Seq2SeqModel(\n",
    "            encoder_decoder_type=\"bart\", \n",
    "            encoder_decoder_name=QA2D_model_path,\n",
    "            cuda_device=gpu_index,\n",
    "            args=model_args\n",
    "        )\n",
    "\n",
    "        print('Loading Replacement Generator module >>>>>>>>')\n",
    "        self.replacement_generator = Distractor_Generation(sense2vec_path = sense_to_vec_path, T = 0.7)\n",
    "\n",
    "        self.corpus_recs = corpus_recs\n",
    "        self.ners = read_json(ner_json)\n",
    "        self.qas = read_json(qas_json)\n",
    "\n",
    "\n",
    "    def _load_passage_entities(self, id_):\n",
    "        passage_entities = []\n",
    "        for ent_text, ent_type, _ in self.ners[id_]:\n",
    "            passage_entities.append(f'{ent_text}:::{ent_type}') # group by entity name and type as in the QAS file\n",
    "        return passage_entities\n",
    "    \n",
    "    def _load_precomputed_qas_for_entities(self, id_, passage_entities):\n",
    "        if id_ not in self.qas:\n",
    "            print(f\"missing id: {id_}\")\n",
    "            return None\n",
    "        QA_for_sample = self.qas[id_]\n",
    "        QA_pairs = []\n",
    "        for entity in passage_entities:\n",
    "            if entity in QA_for_sample:\n",
    "                ent_text, ent_type = entity.split(':::')\n",
    "                question, answer = QA_for_sample[entity]\n",
    "                QA_pairs.append({'question': question, 'answer': answer, 'answer_type': ent_type})\n",
    "            else:\n",
    "                print(f\"missing entity: {entity} for id: {id_}\")\n",
    "                return None\n",
    "        if len(QA_pairs) == 0:\n",
    "            print(f\"zero length pairs for id: {id_}\")\n",
    "            return None\n",
    "        return QA_pairs \n",
    "        \n",
    "\n",
    "    def generate_supported_claims(self, sample):\n",
    "        texts, id_ = sample['text'], str(sample['id'])\n",
    "\n",
    "        # Step 1: load entities in text\n",
    "        passage_entities = self._load_passage_entities(id_)\n",
    "        if len(passage_entities) == 0: # no NERs\n",
    "            return None \n",
    "\n",
    "        # Step 2: load precomputed QAs for entities\n",
    "        QA_pairs = self._load_precomputed_qas_for_entities(id_, passage_entities)\n",
    "        if QA_pairs is None:\n",
    "            return None\n",
    "\n",
    "        # Step 3: QA2D\n",
    "        to_predict = [qa['question'] + ' [SEP] ' + qa['answer'] for qa in QA_pairs]\n",
    "        results = []\n",
    "        # try:\n",
    "        results = self.QA2D_model.predict(to_predict)\n",
    "        # except:\n",
    "            # return None\n",
    "        if len(results) == 0:\n",
    "            print(f\"zero length results for id: {id_}\")\n",
    "            return None\n",
    "\n",
    "        assert len(results) == len(QA_pairs)\n",
    "\n",
    "        claims_for_sample = OrderedDict()\n",
    "        for ent, claim in zip(passage_entities, results):\n",
    "            claims_for_sample[ent] = claim\n",
    "        return claims_for_sample\n",
    "\n",
    "    def generate_refute_global_claims(self, sample):\n",
    "        texts, id_ = sample['text'], str(sample['id'])\n",
    "\n",
    "        # Step 1: load entities in text\n",
    "        passage_entities = self._load_passage_entities(id_)\n",
    "        if len(passage_entities) == 0: # no NERs\n",
    "            return None \n",
    "        \n",
    "        # Step 2: get entity replacement\n",
    "        entity_replacement_dict = {} # get replacement beforehand to save time\n",
    "\n",
    "        valid_entities = set()\n",
    "        for ent in passage_entities:\n",
    "            ent_text, _ = ent.split(':::')\n",
    "            replacement = self.replacement_generator.get_options(ent_text)\n",
    "            if replacement is not None:\n",
    "                entity_replacement_dict[ent_text] = replacement\n",
    "                valid_entities.add(ent)\n",
    "\n",
    "        # Step 3: load precomputed QAs for entities\n",
    "        QA_pairs = self._load_precomputed_qas_for_entities(id_, passage_entities)\n",
    "        if QA_pairs is None:\n",
    "            return None\n",
    "\n",
    "        # Step 4: Answer Replacement\n",
    "        to_predict = []\n",
    "        replace_type = []\n",
    "        replace_keys = []\n",
    "        for qa in QA_pairs:\n",
    "            ans_ent_text = qa['answer']\n",
    "            ans_ent_type = qa['answer_type']\n",
    "            if ans_ent_text == \"\" or ans_ent_type == \"\":\n",
    "                continue\n",
    "            replacement = entity_replacement_dict.get(ans_ent_text)\n",
    "            if replacement is not None:\n",
    "                to_predict.append(qa['question'] + ' [SEP] ' + replacement[0])\n",
    "                replace_keys.append(f\"{ans_ent_text}:::{ans_ent_type}\")\n",
    "                replace_type.append(ans_ent_type)\n",
    "        \n",
    "        # Step 5: QA2D\n",
    "        if len(to_predict) == 0:\n",
    "            return None\n",
    "        results = []\n",
    "        try:\n",
    "            results = self.QA2D_model.predict(to_predict)\n",
    "        except:\n",
    "            return None\n",
    "        if len(results) == 0:\n",
    "            return None\n",
    "        \n",
    "        claims_for_sample = OrderedDict()\n",
    "        for ent, claim in zip(replace_keys, results):\n",
    "            claims_for_sample[ent] = claim\n",
    "        return claims_for_sample\n",
    "\n",
    "\n",
    "    def generate(self, claims_json, claim_type: str, save_every=0, cont=False):\n",
    "        claim_type = claim_type.lower()\n",
    "        assert claim_type in [\"supported\", \"refuted\"]\n",
    "        start = 0\n",
    "        if Path(claims_json).is_file():\n",
    "            if cont:\n",
    "                generated_claims = read_json(claims_json)\n",
    "                print(f\"file exists: {claims_json}, completed: {len(generated_claims)-1}/{len(self.corpus_recs)}\")\n",
    "                start = len(generated_claims)\n",
    "            else:\n",
    "                raise FileExistsError(f\"File already exists: {claims_json} !!!\")\n",
    "        else:\n",
    "            generated_claims = dict() # ordered since P3.7\n",
    "        cnt = 1\n",
    "        for sample in tqdm(self.corpus_recs[start:], initial=start, total=len(self.corpus_recs)):\n",
    "            id_ = str(sample['id'])\n",
    "            if claim_type == \"supported\":\n",
    "                claims = self.generate_supported_claims(sample)\n",
    "            elif claim_type == \"refuted\":\n",
    "                claims = self.generate_refute_global_claims(sample)\n",
    "            if claims is None:\n",
    "                claims = {}\n",
    "            generated_claims[id_] = claims\n",
    "            cnt += 1\n",
    "            if save_every > 0 and cnt % save_every == 0:\n",
    "                write_json(claims_json, generated_claims)\n",
    "\n",
    "        write_json(claims_json, generated_claims)\n",
    "\n",
    "def qacg(input_text):\n",
    "    corpus_recs_dev = [{\"id\":1, \"text\":input_text}]\n",
    "    extract_ners(corpus_recs_dev, Path(QACG_ROOT, \"tmp_ners.json\"))\n",
    "    generate_qas(corpus_recs_dev, Path(QACG_ROOT, \"tmp_ners.json\"), Path(QACG_ROOT, \"tmp_qas.json\"))\n",
    "            \n",
    "    confs = [\n",
    "        (corpus_recs_dev, \"tmp\")\n",
    "    ]\n",
    "    # increment filename until free:\n",
    "    i = 1\n",
    "    while Path(QACG_ROOT, f\"tmp_sup_claims_{i}.json\").is_file():\n",
    "        i += 1\n",
    "    for corpus_recs, name in confs:\n",
    "        claim_generator = ClaimGenerator(corpus_recs, \n",
    "                                    ner_json=Path(QACG_ROOT, f\"{name}_ners.json\"), \n",
    "                                    qas_json=Path(QACG_ROOT, f\"{name}_qas.json\"), \n",
    "                                    QA2D_model_path=\"/home/ullriher/ullriher/data/qacg/QA2D_model\", \n",
    "                                    sense_to_vec_path=\"/home/ullriher/ullriher/data/qacg/s2v_old\")\n",
    "\n",
    "        claim_generator.generate(Path(QACG_ROOT, f\"{name}_sup_claims_{i}.json\"), \"supported\", save_every=100)\n",
    "        #claim_generator.generate(Path(QACG_ROOT, f\"{name}_ref_claims.json\"), \"refuted\", save_every=100, cont=True)\n",
    "    return read_json(Path(QACG_ROOT, f\"tmp_sup_claims_{i}.json\"))[\"1\"].values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load /mnt/data/factcheck/claim_extraction/clef2018_task1_cw_debates/data/English/Task1-English-Vice-Presidential.txt to string\n",
    "with open(\"/mnt/data/factcheck/claim_extraction/clef2018_task1_cw_debates/data/English/Task1-English-Vice-Presidential.txt\") as f:\n",
    "    debate = f.read()\n",
    "#keep only middle column\n",
    "debate = debate.split(\"\\n\")\n",
    "debate = [s.split(\"\\t\")[2] for s in debate if len(s.split(\"\\t\")) > 2]\n",
    "debate = \"\\n\".join(debate[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-15 01:21:13 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4def1a3d29f4400492d17aafc9450b1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.4.1.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-15 01:21:13 INFO: Loading these models for language: en (English):\n",
      "=========================\n",
      "| Processor | Package   |\n",
      "-------------------------\n",
      "| tokenize  | combined  |\n",
      "| ner       | ontonotes |\n",
      "=========================\n",
      "\n",
      "2024-02-15 01:21:13 INFO: Use device: gpu\n",
      "2024-02-15 01:21:13 INFO: Loading: tokenize\n",
      "2024-02-15 01:21:14 INFO: Loading: ner\n",
      "2024-02-15 01:21:14 INFO: Done loading processors!\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.05it/s]\n",
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading QG module >>>>>>>>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QG module loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:03<00:00,  3.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#invalid samples: 0\n",
      "Loading QA2D module >>>>>>>>\n",
      "Loading Replacement Generator module >>>>>>>>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]/home/ullriher/venvs/2023feb/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:397: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `None` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "/home/ullriher/venvs/2023feb/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:407: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `None` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.\n",
      "  warnings.warn(\n",
      "/home/ullriher/venvs/2023feb/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:433: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
      "  warnings.warn(\n",
      "/home/ullriher/venvs/2023feb/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:452: UserWarning: `num_beams` is set to 1. However, `length_penalty` is set to `2.0` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `length_penalty`.\n",
      "  warnings.warn(\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.95s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_values(['The first and only vice presidential debate of 2016 is first.', 'Barbara Johns led a walkout with Hillary Clinton that led to the Brown v. Board of Education decision.', 'The name of the debate between Tim Kaine and Mike Pence is Donald Trump.', 'Elaine is the anchor for CBSN.', 'The name of the debate between Tim Kaine and Mike Pence is the United States.', 'The enthusiastic audience will come to the debate between Tim Kaine and Mike Pence tonight.', 'Pence is the governor of Virginia.', 'Kaine will moderate the debate between Mike Pence and Tim Kaine.', 'Longwood University is located in Farmville.', 'The name of the debate between Tim Kaine and Mike Pence is Russia.', 'Longwood University is located in Virginia.', \"The name of the debate between Tim Kaine and Mike Pence is Hillary Clinton's.\", 'Tim Kaine will moderate the debate between Mike Pence and Senator Ted Cruz.', 'Hillary Clinton is Clinton.', 'The name of the debate between Tim Kaine and Mike Pence is Obama.', 'The name of the debate between Tim Kaine and Mike Pence is Vladimir Putin.', 'Barbara Johns led a walkout of Moton High School.', 'The first and only vice presidential debate of 2016 is at Longwood University.', 'Mike Pence is the governor of Virginia.', 'The name of the debate between Tim Kaine and Mike Pence is 67 percent.', 'The name of the debate between Tim Kaine and Mike Pence is Washington, D.C..', 'The name of the debate between Tim Kaine and Mike Pence is the Childrens Defense Fund.', 'The name of the debate between Tim Kaine and Mike Pence is Methodist.', 'The name of the debate between Tim Kaine and Mike Pence is Trump.', 'The name of the debate between Tim Kaine and Mike Pence is Middle East.', 'The Commission on Presidential Debates sponsored the first and only vice presidential debate of 2016.', \"Barbara Johns'walkout led to the Brown v. Board of Education decision.\", 'Barbara Johns led a walkout with Hillary.', 'Tim Kaine and Mike Pence served in the U.S. Marines.', 'Lloyd Bentsen said that the debate was not about qualifications for the vice presidency.', 'Barbara Johns walked out of her high school sixty-five years ago.', 'Tim Kaine and Mike Pence are proud fathers of U.S. Marines.', 'The name of the debate between Tim Kaine and Mike Pence is state.', 'The debate between Tim Kaine and Mike Pence is 90 minutes long.', 'The name of the debate between Tim Kaine and Mike Pence is Indiana.', 'Lloyd Bentsen said that the debate was not about qualifications for the vice presidency tomorrow night.', 'The name of the debate between Tim Kaine and Mike Pence is one.', 'The name of the debate between Tim Kaine and Mike Pence is South.', 'Elaine Quijano is an anchor at CBSN.', 'The name of the debate between Tim Kaine and Mike Pence is Syria.', 'The first vice presidential debate took place in 2016.', 'There will be nine segments in the debate.', 'Arkansas is the name of the debate between Tim Kaine and Mike Pence.', 'The name of the debate between Tim Kaine and Mike Pence is Norwood University.', 'The name of the debate between Tim Kaine and Mike Pence is Ukraine.', 'The name of the debate between Tim Kaine and Mike Pence is 60 percent.', 'The name of the debate between Tim Kaine and Mike Pence is 65 percent.', 'The name of the debate between Tim Kaine and Mike Pence is Chicago.', 'The name of the debate between Tim Kaine and Mike Pence is the last seven-and-a-half years.', 'Elaine Quijano is a correspondent for CBS News.', 'The name of the debate between Tim Kaine and Mike Pence is hour by hour.', 'The name of the debate between Tim Kaine and Mike Pence is Mexicans.', 'The name of the debate between Tim Kaine and Mike Pence is American.', 'Congress is the name of the debate between Tim Kaine and Mike Pence.', 'Each candidate will have to answer a question two minutes.', 'The Commission sponsored the first and only vice presidential debate of 2016.', 'The name of the debate between Tim Kaine and Mike Pence is 65 years ago.', 'Lloyd Bentsen said that the debate was not about qualifications for the vice presidency twenty-eight years ago.', 'The name of the debate between Tim Kaine and Mike Pence is the Clinton Foundation.', 'The name of the debate between Tim Kaine and Mike Pence is the Marine Corps.', 'The debate between Tim Kaine and Mike Pence is in evening.', 'The name of the debate between Tim Kaine and Mike Pence is an African-American.', 'The name of the debate between Tim Kaine and Mike Pence is Southern Indiana.', 'Barbara Johns walked out of Moton High School.', \"Brown v. Board of Education was the result of Barbara Johns' walkout.\", 'The name of the debate between Tim Kaine and Mike Pence is Obamacare.', 'The name of the debate between Tim Kaine and Mike Pence is Americans.', 'The name of the debate between Tim Kaine and Mike Pence is just a moment.', 'The name of the debate between Tim Kaine and Mike Pence is today.', 'America is the name of the debate between Tim Kaine and Mike Pence.', 'Elaine Quijano is the anchor for CBSN.'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qacg(debate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-15 01:21:29,734\tINFO util.py:159 -- Outdated packages:\n",
      "  ipywidgets==7.7.2 found, needs ipywidgets>=8\n",
      "Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "2024-02-15 01:21:29,934\tINFO util.py:159 -- Outdated packages:\n",
      "  ipywidgets==7.7.2 found, needs ipywidgets>=8\n",
      "Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41fa54360b4b4ab389c89d7eba6dd0f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    BitsAndBytesConfig\n",
    ")\n",
    "from transformers import TrainingArguments\n",
    "import os, wandb\n",
    "from trl import SFTTrainer\n",
    "from peft import LoraConfig, PeftModel\n",
    "from peft import AutoPeftModelForCausalLM\n",
    "from vllm import LLM, SamplingParams\n",
    "import torch\n",
    "import os\n",
    "import pysbd\n",
    "from datasets import load_dataset\n",
    "seg = pysbd.Segmenter(language=\"en\", clean=False)\n",
    "\n",
    "FORMAT_1 = \"\"\"Extract all facts from this Wikipedia article:\n",
    "{context}\n",
    "----\n",
    "You must print one claim per line, as a sentence that does not require additional context to interpret, print as many lines as it takes to cover all the input facts.\"\"\"\n",
    "\n",
    "\n",
    "def format_prompt(input_text, hide_output=False, format=FORMAT_1):\n",
    "    result = [\n",
    "        {\"role\": \"user\", \"content\": format.format(context=input_text)}\n",
    "    ]\n",
    "    return result\n",
    "\n",
    "model_name = \"/home/ullriher/ullriher/models/claim_extraction/paper/mistral_7250872\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "device_map = \"auto\"\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name, \n",
    "    device_map=device_map, # to use max gpu resources if exist\n",
    ")\n",
    "\n",
    "def mistral(input_text, max_new_tokens=512):\n",
    "    eval_prompt = format_prompt(input_text)\n",
    "    model_input = tokenizer.apply_chat_template(eval_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        print()\n",
    "        output = tokenizer.decode(model.generate(model_input, max_new_tokens=max_new_tokens)[0], skip_special_tokens=True)\n",
    "        return [sent.strip() for sent in seg.segment(output.split(\"[/INST]\")[-1])]\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Tim Kaine is running for vice president.',\n",
       " 'Tim Kaine is a senator.',\n",
       " 'Tim Kaine is on the Democratic ticket.']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mistral(debate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ullriher/venvs/2023feb/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:433: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Senator Kaine is a politician. Senator Kaine is a politician. Senator Kaine is a politician.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t5(debate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Senator Kaine is a politician.',\n",
       " 'Senator Kaine is an anchor.',\n",
       " 'The vice presidential debate will be held in Virginia.',\n",
       " 'Senator Kaine has been in the vice presidential debate.',\n",
       " 'Representatives of the United States and the United States have been in the vice presidential debate since 1996.',\n",
       " 'Senator Tim Kaine is a president.',\n",
       " 'Governor Pence will be in the vice presidential debate in 2016.',\n",
       " 'Senator Kaine was in the vice presidential debate.',\n",
       " 'Tim Kaine has two minutes to answer the opening question for the vice presidential debate.',\n",
       " 'Mike Pence hosted the vice presidential debate in 2016.',\n",
       " 'The Vice Presidential Debates will be held in Virginia.',\n",
       " 'Both candidates have an enthusiastic audience.',\n",
       " 'Senator Tim Kaine is an anchor for CBS News.',\n",
       " 'Governor Pence will be a speaker on the vice presidential debate in 2016.',\n",
       " 'The vice presidential debate will be a 90-minute debate.',\n",
       " 'Senator Tim Kaine has been in the vice presidential debate since November.',\n",
       " 'Joey McLaren is an anchor for CBS News.',\n",
       " 'The vice presidential debate will be held in Virginia.',\n",
       " 'There will be a vice presidential debate.',\n",
       " 'Joe Fenway has worked with Senator Tim Kaine.',\n",
       " 'Sami Pamela has been on the vice presidential debate since 2008.',\n",
       " 'Phil Cains has been on the subject of presidential leadership for over twenty years.',\n",
       " 'Governor Pence has been on the subject of presidential debate for 90 minutes.',\n",
       " 'Bill Gates hosts a vice presidential debate in 2016.',\n",
       " 'Senator Kaine is a president.',\n",
       " 'Mike Pence hosts the vice presidential debate.',\n",
       " 'Senator Mike Pence was on CBS.',\n",
       " 'John McCain is a president.',\n",
       " 'Tim Kaine was in the vice presidential debate for nine years.',\n",
       " 'The vice presidential debate takes place in Virginia.',\n",
       " 'Senator Bill Kaine is an anchor at CBSN.',\n",
       " 'Mike Pence hosted the vice presidential debate at Longwood University.',\n",
       " 'Tim Kaine is an anchor for CBSN.']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t5_diverse(debate, num_claims=33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt4, t5, t5_diverse, qacg, mistral(debate)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
